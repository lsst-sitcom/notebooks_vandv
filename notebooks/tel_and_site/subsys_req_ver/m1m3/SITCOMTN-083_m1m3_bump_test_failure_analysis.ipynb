{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b198b815-b223-441f-99bb-c7cd4f0c5cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [SITCOM-772] - M1M3 Actutator Bump Test Failure Analysis\n",
    "\n",
    "Notebook containing data analysis for the [LVV-T229] and [LVV-T238] test cases. \n",
    "\n",
    "Scripts used to run these test cases can be found respectively in:\n",
    "\n",
    "+ [M13T002.py] \n",
    "+ [M13T018.py]     \n",
    "\n",
    "Note that [LVV-T229] ([M13T002.py]) can also be executed using the SAL Script `check_actuators.py`. \n",
    "The code used to run the bump test is not relevant to this analysis.\n",
    "\n",
    "\n",
    "## Goal:\n",
    "---\n",
    "\n",
    "Bases on the hiphotesis that a high failure rate could indicate a problem with an actuator, \n",
    "we want to obtain a list of actuators with the highest failure rate. \n",
    "This is particular useful to keep track of trouble makers.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "---\n",
    "We will obtaint the relative rate of failures, normalizing the total number of failures to be equal to one. \n",
    "In this way, we will determine which actuators give more trouble when compared to others. \n",
    "\n",
    "\n",
    "## Results\n",
    "---\n",
    "Results can be found at associated technote:\n",
    "\n",
    "+ [SITCOMTN-083: M1M3 mirror cell bump testing] \n",
    "\n",
    "\n",
    "[LVV-T229]: https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T229\n",
    "[LVV-T238]: https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T238\n",
    "\n",
    "[M13T002.py]: https://github.com/lsst-ts/ts_m1m3supporttesting/blob/develop/M13T002.py\n",
    "[M13T018.py]: https://github.com/lsst-ts/ts_m1m3supporttesting/blob/develop/M13T018.py\n",
    "\n",
    "[SITCOM-772]: https://jira.lsstcorp.org/browse/SITCOM-772\n",
    "\n",
    "[SITCOMTN-083: M1M3 mirror cell bump testing]: https://sitcomtn-083.lsst.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c24055-70e0-4f20-b512-d39e08d85857",
   "metadata": {},
   "source": [
    "## Preparing the Notebook\n",
    "---\n",
    "\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913a152-d9a4-4bc9-9551-e27ce5cd954f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "\n",
    "try:\n",
    "    from lsst.ts.xml.tables.m1m3 import FATable\n",
    "except ImportError:\n",
    "    from lsst.ts.criopy.M1M3FATable import FATABLE as FATable\n",
    "\n",
    "from lsst_efd_client import EfdClient\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a9f71-7f6a-44fe-a0f4-08a9c4cc9db3",
   "metadata": {},
   "source": [
    "## Collecting data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257fe8cb-233c-45cd-bb8e-1ace99fe60f4",
   "metadata": {},
   "source": [
    "### Setting up times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc009a-bbb0-442d-8989-e9678d47f75f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Times of a specific bump test\n",
    "# start = Time(\"2023-04-11T16:00:00.\", format=\"isot\", scale='utc')\n",
    "# end = Time(\"2023-04-11T18:51:14\", format=\"isot\", scale='utc')\n",
    "\n",
    "# Times for multiple bump tests over the years\n",
    "start = Time(\"2018-10-17T10:00:00\", format=\"isot\", scale=\"utc\")\n",
    "end = Time(Time.now(), scale=\"utc\", format=\"isot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca775c8f-5625-4ab4-8189-cf0dab5e3630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making a client to the desired database\n",
    "# client = EfdClient('summit_efd')\n",
    "client = EfdClient(\"idf_efd\")  # It contains lost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d3b24-0cbc-4238-b6ae-11b1e23cd2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Not working for 'ifd_efd' client\n",
    "# schema = await client.get_schema('lsst.sal.MTM1M3.logevent_forceActuatorBumpTestStatus')\n",
    "# schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f63d2-dd7a-4290-9afc-b3d9c3726a82",
   "metadata": {},
   "source": [
    "### Getting bump test data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67550-b188-4bb7-9648-7c023e7060f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bump = await client.select_time_series(\n",
    "    \"lsst.sal.MTM1M3.logevent_forceActuatorBumpTestStatus\", \"*\", start, end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4557ead-5e92-401d-88b4-af8c9cdb8a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bump[bump.actuatorId != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50755bd7-94ff-473c-bd51-1a229d78b661",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "---\n",
    "\n",
    "Here we define a couple of helper function to interact with the FATable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531d843-b5ce-4096-a70a-4ea9b0b474d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting primary {index: id} dictionary\n",
    "m1m3_actuator_index_id_table: dict[int, int] = dict(\n",
    "    [(fa.index, fa.actuator_id) for fa in FATable]\n",
    ")\n",
    "\n",
    "# Getting secondary {index: id} dictionary\n",
    "m1m3_actuator_sindex_id_table: dict[int, int] = dict(\n",
    "    [(fa.s_index, fa.actuator_id) for fa in FATable if fa.s_index is not None]\n",
    ")\n",
    "\n",
    "# Getting primary {id: index} dictionary\n",
    "m1m3_actuator_id_index_table: dict[int, int] = dict(\n",
    "    [(fa.actuator_id, fa.index) for fa in FATable]\n",
    ")\n",
    "\n",
    "\n",
    "def get_id(index):\n",
    "    if index in m1m3_actuator_index_id_table.keys():\n",
    "        return m1m3_actuator_index_id_table[index]\n",
    "    else:\n",
    "        raise ValueError(\"You provides an invalid actuator id\")\n",
    "\n",
    "\n",
    "def get_sid(index):\n",
    "    if index in m1m3_actuator_sindex_id_table.keys():\n",
    "        return m1m3_actuator_sindex_id_table[index]\n",
    "    else:\n",
    "        raise ValueError(\"You provides an invalid index\")\n",
    "\n",
    "\n",
    "def get_m1m3_actuator_ids() -> list[int]:\n",
    "    \"\"\"Get a list of the M1M3 actuator ids.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `list`[ `int` ]\n",
    "        List of M1M3 actuator ids.\n",
    "    \"\"\"\n",
    "    return list(m1m3_actuator_id_index_table.keys())\n",
    "\n",
    "\n",
    "def is_actuator_dual(actuator_id, actuator_list=FATable):\n",
    "    actuator_id = int(actuator_id)\n",
    "\n",
    "    if actuator_id not in get_m1m3_actuator_ids():\n",
    "        raise ValueError(f\"Invalid actuator id: {actuator_id}.\")\n",
    "    else:\n",
    "        actuator = next(\n",
    "            (act for act in actuator_list if act.actuator_id == actuator_id), None\n",
    "        )\n",
    "\n",
    "        return actuator is not None and actuator.actuator_type.name == \"DAA\"\n",
    "\n",
    "\n",
    "def get_orientation(actuator_id, actuator_list=FATable):\n",
    "    # Define the mapping\n",
    "    orientation_mapping = {\n",
    "        \"Y_PLUS\": \"Y+\",\n",
    "        \"Y_MINUS\": \"Y-\",\n",
    "        \"X_PLUS\": \"X+\",\n",
    "        \"X_MINUS\": \"X-\",\n",
    "        \"NA\": \"NA\",\n",
    "    }\n",
    "\n",
    "    # Check for invalid actuator_id\n",
    "    if actuator_id not in get_m1m3_actuator_ids():\n",
    "        raise ValueError(f\"Invalid actuator id: {actuator_id}.\")\n",
    "\n",
    "    # Search for the actuator with a given actuator_id and return mapped orientation\n",
    "    for actuator in actuator_list:\n",
    "        if actuator.actuator_id == actuator_id:\n",
    "            # Get the original orientation name and map it\n",
    "            orientation = actuator.orientation.name\n",
    "            return orientation_mapping.get(orientation)\n",
    "\n",
    "\n",
    "def get_xy_position(actuator_list=FATable):\n",
    "    # Collect all x and y positions using list comprehensions\n",
    "    xpos = [actuator.x_position for actuator in actuator_list]\n",
    "    ypos = [actuator.y_position for actuator in actuator_list]\n",
    "\n",
    "    return xpos, ypos\n",
    "\n",
    "\n",
    "def id_position_map(actuator_list=FATable):\n",
    "    return {\n",
    "        actuator.actuator_id: (actuator.x_position, actuator.y_position)\n",
    "        for actuator in actuator_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4a258-a0e1-45fd-9f9a-63737a4a4a28",
   "metadata": {},
   "source": [
    "### Getting status columns\n",
    "---\n",
    "\n",
    "Here we are removing unwanted columns to keep only columns of interest. At the same time, we are renaming columns starting with `primaryTest` (`secondaryTest`) to `primaryTest_Status` (`secondaryTest_Status`) to contain the status name in case of `PASSED` and `FAILED` status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ad628-6fed-4238-81ff-feeb6a04c9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_and_map_columns(bump):\n",
    "    # Making private_rcvStamp as the index\n",
    "    bump = bump.set_index(\"private_rcvStamp\").copy()\n",
    "    bump.index = pd.to_datetime(bump.index, unit=\"s\")\n",
    "\n",
    "    # Filtering columns\n",
    "    columns_to_extract = bump.filter(\n",
    "        regex=\"^actuatorID|^private_rcvStamp|^primaryTest(?!Timestamps)|^secondaryTest(?!Timestamps)\"\n",
    "    ).columns\n",
    "    bump_status = bump[columns_to_extract].copy()\n",
    "\n",
    "    for col in bump_status.columns:\n",
    "        if \"Test\" in col:\n",
    "            index = int(col.split(\"Test\")[1].split(\"_\")[0])\n",
    "\n",
    "            cylinder = col.split(\"Test\")[0]\n",
    "\n",
    "            if cylinder == \"primary\":\n",
    "                actuator_id = get_id(int(index))\n",
    "            elif cylinder == \"secondary\":\n",
    "                actuator_id = get_sid(int(index))\n",
    "\n",
    "            new_col_name = f\"{cylinder}Test_Status_{actuator_id}\"\n",
    "            bump_status.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "    # Mapping status\n",
    "    status_mapping = {\n",
    "        1: \"NOTTESTED\",\n",
    "        2: \"TESTINGPOSITIVE\",\n",
    "        3: \"TESTINGPOSITIVEWAIT\",\n",
    "        4: \"TESTINGNEGATIVE\",\n",
    "        5: \"TESTINGNEGATIVEWAIT\",\n",
    "        6: \"PASSED\",\n",
    "        7: \"FAILED\",\n",
    "    }\n",
    "\n",
    "    # Iterate over the columns\n",
    "    for column in bump_status.columns:\n",
    "        if \"Status\" in column:\n",
    "            # Replace the column values using the status_mapping dictionary\n",
    "            bump_status[column] = bump_status[column].replace(status_mapping)\n",
    "\n",
    "    return bump_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842c022-bb49-4caa-874f-53a051f9bd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting filtered bump data frame\n",
    "bump_status = filter_and_map_columns(bump)\n",
    "\n",
    "bump_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872a55e-cfa3-4dc9-8b97-6a13696f3929",
   "metadata": {},
   "source": [
    "### Checking, filtering and sorting data frame columns\n",
    "---\n",
    "\n",
    "Here we are just checking the integrity of the bump status table, since it was modified with the `filter_and_map_columns` one step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d3aea-74a9-4b93-ac78-56db41c4ceda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_bump_data(bump_status):\n",
    "    try:\n",
    "        # Assert integrity of number of actuators being tested\n",
    "        primary_test_count = sum(bump_status.columns.str.contains(\"primaryTest_Status\"))\n",
    "        secondary_test_count = sum(\n",
    "            bump_status.columns.str.contains(\"secondaryTest_Status\")\n",
    "        )\n",
    "\n",
    "        assert primary_test_count == 156, log.warning(\n",
    "            f\"Expected primary test count: 156, Actual count: {primary_test_count}\"\n",
    "        )\n",
    "        assert secondary_test_count == 112, log.warning(\n",
    "            f\"Expected secondary test count: 112, Actual count: {secondary_test_count}\"\n",
    "        )\n",
    "\n",
    "        # Checking for duplicated columns\n",
    "        duplicate_columns = bump_status.columns[bump_status.columns.duplicated()]\n",
    "        assert duplicate_columns.empty, log.warning(\n",
    "            f\"Duplicated columns {duplicate_columns}\"\n",
    "        )\n",
    "\n",
    "        # Sorting bump data frame to show first primary status and then secondary\n",
    "        primary_columns = [\n",
    "            col for col in bump_status.columns if \"primaryTest_Status\" in col\n",
    "        ]\n",
    "        secondary_columns = [\n",
    "            col for col in bump_status.columns if \"secondaryTest_Status\" in col\n",
    "        ]\n",
    "\n",
    "        sorted_columns = sorted(\n",
    "            bump_status.columns,\n",
    "            key=lambda col: (\n",
    "                col not in primary_columns,\n",
    "                col not in secondary_columns,\n",
    "                col,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        sorted_df_bump = bump_status[sorted_columns]\n",
    "\n",
    "        return sorted_df_bump\n",
    "\n",
    "    except AssertionError as e:\n",
    "        log.warning(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604b2a1-53a0-4de0-966a-cc4297bd4613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_bumps = process_bump_data(bump_status)\n",
    "\n",
    "df_bumps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e4cb4-a268-4ee8-a400-be4ee3c3d3ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculating rate of failures\n",
    "---\n",
    "\n",
    "The analysis starts here.\n",
    "\n",
    "### A few more helper functions to run the analysis and visualition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71f181-54b5-4a26-96c5-18d16008fa7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_orientation_column(df):\n",
    "    # Create an empty list to store the orientation values\n",
    "    orientation = []\n",
    "\n",
    "    # Iterate over the index values (actuator_ids) in the DataFrame\n",
    "    for actuator_id in df[\"actuator_id\"]:\n",
    "        # Get the orientation using the actuator_id\n",
    "        orientation_value = get_orientation(int(actuator_id))\n",
    "        # Append the orientation value to the list\n",
    "        orientation.append(orientation_value)\n",
    "\n",
    "    # Add the orientation column to the DataFrame\n",
    "    df[\"Orientation\"] = orientation\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def map_status_int_to_str(df):\n",
    "    # change the states values from int to str\n",
    "    status_mapping = {\n",
    "        1: \"NOTTESTED\",\n",
    "        2: \"TESTINGPOSITIVE\",\n",
    "        3: \"TESTINGPOSITIVEWAIT\",\n",
    "        4: \"TESTINGNEGATIVE\",\n",
    "        5: \"TESTINGNEGATIVEWAIT\",\n",
    "        6: \"PASSED\",\n",
    "        7: \"FAILED\",\n",
    "    }\n",
    "\n",
    "    # Iterate over the columns\n",
    "    for column in df.columns:\n",
    "        if \"Status\" in column:\n",
    "            # Replace the column values using the status_mapping dictionary\n",
    "            df[column] = df[column].replace(status_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def map_status_str_to_int(df):\n",
    "    # change the states values from str to int\n",
    "    status_mapping = {\n",
    "        \"NOTTESTED\": 1,\n",
    "        \"TESTINGPOSITIVE\": 2,\n",
    "        \"TESTINGPOSITIVEWAIT\": 3,\n",
    "        \"TESTINGNEGATIVE\": 4,\n",
    "        \"TESTINGNEGATIVEWAIT\": 5,\n",
    "        \"PASSED\": 6,\n",
    "        \"FAILED\": 7,\n",
    "    }\n",
    "\n",
    "    # Iterate over the columns\n",
    "    for column in df.columns:\n",
    "        if \"Status\" in column:\n",
    "            # Replace the column values using the status_mapping dictionary\n",
    "            df[column] = df[column].replace(status_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_individual_bump_tests(column, df_bumps):\n",
    "    \"\"\"This function finds the individual bump tests in the DataFrame for a given column\n",
    "    associated to an actuator.\n",
    "    It finds the failed and successful tests and returns them as a list of DataFrames.\n",
    "\n",
    "    A bump test is considered successful if it follows the sequence of states:\n",
    "    \"NOTTESTED\"-> \"TESTINGPOSITIVE\"->\"TESTINGPOSITIVEWAIT\"-> \"TESTINGNEGATIVE\"->\"TESTINGNEGATIVEWAIT\"-> \"PASSED\"\n",
    "\n",
    "    A failed test on the other hands ends in a \"FAILED\" state, and can fail at any point in the sequence.\n",
    "    Possible failed tests sequences are:\n",
    "    \"NOTTESTED\"-> \"TESTINGPOSITIVE\"->\"TESTINGPOSITIVEWAIT\"-> \"TESTINGNEGATIVE\"->\"TESTINGNEGATIVEWAIT\"-> \"FAILED\"\n",
    "    \"NOTTESTED\"-> \"TESTINGPOSITIVE\"->\"TESTINGPOSITIVEWAIT\"-> \"TESTINGNEGATIVE\"-> \"FAILED\"\n",
    "    \"NOTTESTED\"-> \"TESTINGPOSITIVE\"->\"TESTINGPOSITIVEWAIT\"-> \"FAILED\"\n",
    "    \"NOTTESTED\"-> \"TESTINGPOSITIVE\"-> \"FAILED\"\n",
    "\n",
    "    This functions returns a two lists of DataFrames, one for successful tests and one for failed tests.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    column :str\n",
    "        Column name in the DataFrame that contains the actuator states\n",
    "    df_bumps : _type_\n",
    "        DataFrame containing the actuator states\n",
    "    Returns\n",
    "    -------\n",
    "    tuple : list, list\n",
    "        A tuple of two lists containing the DataFrames for successful and failed tests\n",
    "    \"\"\"\n",
    "\n",
    "    testing_sequence = [2, 3, 4, 5, 6]\n",
    "    start_state = 1\n",
    "    end_state_failure = 7\n",
    "    end_state_success = 6\n",
    "\n",
    "    # Find the indices where the sequence starts\n",
    "    success_tests_dfs, failed_tests_dfs = [], []\n",
    "\n",
    "    # find all rows that transition from start_state to any other state\n",
    "    # this is needed to find the start of a testing sequence\n",
    "    # because actuators publish the same state multiple times\n",
    "    start_rows = (df_bumps[column] == start_state) & (\n",
    "        df_bumps[column].shift(1) != start_state\n",
    "    )\n",
    "    # these are the indices where bump tests start\n",
    "    start_indices = df_bumps[start_rows].index\n",
    "\n",
    "    # Iterate over the start indices\n",
    "    for timestamp in start_indices:\n",
    "        # Iterate over the sequence length\n",
    "        # A failed bump test does not necessarily follows\n",
    "        # the same sequence as the successful one\n",
    "        # In can be [1, 2, 3, 4, 5, 7]\n",
    "        # or [1, 2, 3, 7]\n",
    "        # or [1, 2, 7]\n",
    "        # depending on where the test failed, so we need to\n",
    "        # Iterate over the sequence and find all possible sequences\n",
    "        for i in range(1, len(testing_sequence)):\n",
    "            sequence = [start_state] + testing_sequence[:i] + [end_state_failure]\n",
    "            # Get the integer position corresponding to the timestamp index\n",
    "            idx = df_bumps.index.get_loc(timestamp)\n",
    "\n",
    "            # Calculate the end index based on the length of the sequence\n",
    "            end_idx = idx + len(sequence)\n",
    "\n",
    "            # Check if the end index is within the range of the DataFrame\n",
    "            if end_idx < len(df_bumps):\n",
    "                # Check if the sequence matches at the corresponding indices\n",
    "                # if so, this is an individual failed bump test\n",
    "                if all(\n",
    "                    df_bumps[column].iloc[idx + i] == state\n",
    "                    for i, state in enumerate(sequence)\n",
    "                ):\n",
    "                    # we extract the individual df for the failed test\n",
    "                    df = df_bumps.iloc[idx:end_idx]\n",
    "                    failed_tests_dfs.append(df)\n",
    "\n",
    "        # same as above, but for successful tests\n",
    "        # a successful follows all the sequence of states [1, 2, 3, 4, 5, 6]\n",
    "        sequence = [start_state] + testing_sequence + [end_state_success]\n",
    "\n",
    "        idx = df_bumps.index.get_loc(timestamp)\n",
    "\n",
    "        # Calculate the end index based on the length of the sequence\n",
    "        end_idx = idx + len(sequence)\n",
    "\n",
    "        # Check if the end index is within the range of the DataFrame\n",
    "        if end_idx < len(df_bumps):\n",
    "            # Check if the sequence matches at the corresponding indices\n",
    "            if all(\n",
    "                df_bumps[column].iloc[idx + i] == state\n",
    "                for i, state in enumerate(sequence)\n",
    "            ):\n",
    "                df = df_bumps.iloc[idx:end_idx]\n",
    "                success_tests_dfs.append(df)\n",
    "    return success_tests_dfs, failed_tests_dfs\n",
    "\n",
    "\n",
    "def calculate_failures(df_bumps):\n",
    "    # Initialize a dictionary to store the failures for each actuator ID\n",
    "    failed_counts = {}\n",
    "    df_bumps = map_status_str_to_int(df_bumps)\n",
    "    # Iterate over the columns\n",
    "    for column in df_bumps.columns:\n",
    "        # Check if the column contains the pattern 'Status_' followed by a number\n",
    "        if re.search(r\"Status_\\d+\", column):\n",
    "            # Extract the actuator ID from the column name\n",
    "            actuator_id = re.search(r\"Status_(\\d+)\", column).group(1)\n",
    "\n",
    "            # Get primary failures\n",
    "            primary_column = f\"primaryTest_Status_{actuator_id}\"\n",
    "\n",
    "            # get all failed and passed bump tests\n",
    "            success_dfs_primary, failed_dfs_primary = find_individual_bump_tests(\n",
    "                primary_column, df_bumps\n",
    "            )\n",
    "            # count failed and passed tests\n",
    "            primary_failures = len(failed_dfs_primary)\n",
    "            primary_successes = len(success_dfs_primary)\n",
    "\n",
    "            # Get secondary failures\n",
    "            secondary_column = f\"secondaryTest_Status_{actuator_id}\"\n",
    "            if secondary_column in df_bumps.columns:\n",
    "                # Same as above, but for the secondary actuators\n",
    "                success_dfs_secondary, failed_dfs_secondary = find_individual_bump_tests(\n",
    "                    secondary_column, df_bumps\n",
    "                )\n",
    "                secondary_failures = len(failed_dfs_secondary)\n",
    "                secondary_successes = len(success_dfs_secondary)\n",
    "                # secondary_failures = (df_bumps[secondary_column] == \"FAILED\").sum()\n",
    "            else:\n",
    "                secondary_failures = None\n",
    "                secondary_successes = None\n",
    "\n",
    "            # Calculate the total failures\n",
    "            total_failures = (\n",
    "                primary_failures\n",
    "                if secondary_failures is None\n",
    "                else primary_failures + secondary_failures\n",
    "            )\n",
    "            # total passed tests\n",
    "            total_passed = (\n",
    "                primary_successes\n",
    "                if secondary_successes is None\n",
    "                else primary_successes + secondary_successes\n",
    "            )\n",
    "            # total tests if failed+passed\n",
    "            total_tests = total_passed + total_failures\n",
    "            # failure rate estimated as the rate of failed over total executed tests\n",
    "            failure_rate = total_failures / total_tests\n",
    "\n",
    "            # Store the failures in the dictionary as a tuple of (primary_failures, secondary_failures, total_failures)\n",
    "            failed_counts[f\"{actuator_id}\"] = (\n",
    "                primary_failures,\n",
    "                primary_successes,\n",
    "                secondary_failures,\n",
    "                secondary_successes,\n",
    "                total_failures,\n",
    "                total_passed,\n",
    "                total_tests,\n",
    "                failure_rate,\n",
    "            )\n",
    "\n",
    "    # Create a new DataFrame from the dictionary of failures\n",
    "    failed_counts_df = pd.DataFrame.from_dict(\n",
    "        failed_counts,\n",
    "        orient=\"index\",\n",
    "        columns=[\n",
    "            \"PrimaryFailures\",\n",
    "            \"PrimaryPassed\",\n",
    "            \"SecondaryFailures\",\n",
    "            \"SecondaryPassed\",\n",
    "            \"TotalFailures\",\n",
    "            \"TotalPassed\",\n",
    "            \"TotalTests\",\n",
    "            \"FailureRate\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    failed_counts_df = (\n",
    "        failed_counts_df.reset_index().rename(columns={\"index\": \"actuator_id\"}).copy()\n",
    "    )\n",
    "\n",
    "    # Sort the DataFrame by the failure rate in descending order\n",
    "    sorted_failed_counts_df = failed_counts_df.sort_values(\n",
    "        by=\"FailureRate\", ascending=False\n",
    "    )\n",
    "\n",
    "    # Add orientation column\n",
    "    sorted_failed_counts_df = add_orientation_column(sorted_failed_counts_df).copy()\n",
    "\n",
    "    # Set actuator_id as the index\n",
    "    sorted_failed_counts_df = sorted_failed_counts_df.set_index(\"actuator_id\")\n",
    "    df_bumps = map_status_int_to_str(df_bumps)\n",
    "    return sorted_failed_counts_df\n",
    "\n",
    "\n",
    "def plot_stacked_failures(ax, df_bumps, failures_to_show=15):\n",
    "    # Extract the starting and ending dates from the DataFrame\n",
    "    start_date = df_bumps.index.min()\n",
    "    end_date = df_bumps.index.max()\n",
    "\n",
    "    start_date_formatted = start_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_formatted = end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Passing argument\n",
    "    N = failures_to_show\n",
    "\n",
    "    # Calculate failures on the fly\n",
    "    sorted_failed_counts_df = calculate_failures(df_bumps)\n",
    "\n",
    "    # Extract the number of tests\n",
    "    total_tests = sorted_failed_counts_df[\"TotalTests\"]\n",
    "\n",
    "    # Calculate the frequency of failures, individually\n",
    "    total_frequency = sorted_failed_counts_df[\"TotalFailures\"] / total_tests\n",
    "    pri_frequency = sorted_failed_counts_df[\"PrimaryFailures\"] / total_tests\n",
    "    sec_frequency = sorted_failed_counts_df[\"SecondaryFailures\"].fillna(0) / total_tests\n",
    "\n",
    "    # Create a bar plot for primary failures\n",
    "    ax.bar(\n",
    "        sorted_failed_counts_df.index[0:N],  # Use index here\n",
    "        pri_frequency[0:N],\n",
    "        label=\"Primary\",\n",
    "    )\n",
    "\n",
    "    # Create the bar plot for secondary failures, stacked on top of primary failures\n",
    "    ax.bar(\n",
    "        sorted_failed_counts_df.index[0:N],  # And here\n",
    "        sec_frequency[0:N],\n",
    "        bottom=pri_frequency[0:N],\n",
    "        label=\"Secondary\",\n",
    "    )\n",
    "\n",
    "    # Set the title and labels\n",
    "    plt.suptitle(\n",
    "        f\"Starting Date: {start_date_formatted}   Final Date: {end_date_formatted}\"\n",
    "    )\n",
    "    ax.set_title(\"Frequency of Failures by Actuator ID\")\n",
    "    ax.set_xlabel(\"Actuator ID\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    ax.set_ylim(0, total_frequency.max() + 0.05)\n",
    "\n",
    "    # Rotating X-axis labels\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "\n",
    "    # Display the orientation information as text\n",
    "    for actuator_id, row in sorted_failed_counts_df[0:N].iterrows():\n",
    "        orientation = row[\"Orientation\"]\n",
    "        total_tests = row[\"TotalTests\"]\n",
    "        failed_tests = row[\"TotalFailures\"]\n",
    "        # plots a counter indicating failed_tests/total_tests for each bar\n",
    "        ax.text(\n",
    "            actuator_id,\n",
    "            total_frequency[actuator_id],\n",
    "            f\"{failed_tests}/{total_tests}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "            color=\"k\",\n",
    "        )\n",
    "        # if the actuator is dual, show it\n",
    "        if is_actuator_dual(actuator_id):\n",
    "            ax.text(\n",
    "                actuator_id,\n",
    "                total_frequency[actuator_id] + 0.02,\n",
    "                f\"{orientation}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "                color=\"orange\",\n",
    "            )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def ActuatorsLayout(ax, failures_df, actuator_list=FATable):\n",
    "    \"\"\"From Craig's code\"\"\"\n",
    "\n",
    "    failed_actuators = [int(i) for i in list(failures_df.index)]\n",
    "\n",
    "    ax.set_xlabel(\"X position (m)\")\n",
    "    ax.set_ylabel(\"Y position (m)\")\n",
    "    ax.set_title(\"M1M3 Failed Actuators\", fontsize=12)\n",
    "\n",
    "    ids = get_m1m3_actuator_ids()\n",
    "    xpos, ypos = get_xy_position()\n",
    "\n",
    "    # Circles\n",
    "    ax.plot(xpos, ypos, \"o\", ms=14, color=\"blue\", alpha=0.05, mec=\"red\")\n",
    "\n",
    "    for l, x, y in zip(ids, xpos, ypos):\n",
    "        ax.annotate(\n",
    "            l,\n",
    "            (x, y),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(-5.5, -2),\n",
    "            color=\"blue\",\n",
    "            size=\"xx-small\",\n",
    "        )\n",
    "\n",
    "    # Flag failed actuators with red bold circle\n",
    "    if failed_actuators:\n",
    "        for actuator_id in failed_actuators:\n",
    "            if actuator_id in ids:\n",
    "                index = ids.index(actuator_id)\n",
    "                ax.scatter(\n",
    "                    xpos[index],\n",
    "                    ypos[index],\n",
    "                    marker=\"o\",\n",
    "                    facecolors=\"none\",\n",
    "                    edgecolors=\"red\",\n",
    "                    s=250,\n",
    "                    alpha=0.5,\n",
    "                    linewidths=2,\n",
    "                )\n",
    "\n",
    "    Rhp = 3.1  # Radius in meters\n",
    "    for i in range(6):\n",
    "        theta = 2.0 * np.pi / 6.0 * float(i)\n",
    "        if i == 0:\n",
    "            ax.scatter(\n",
    "                Rhp * np.cos(theta),\n",
    "                Rhp * np.sin(theta),\n",
    "                marker=\"*\",\n",
    "                color=\"green\",\n",
    "                s=30,\n",
    "                alpha=0.3,\n",
    "            )\n",
    "        else:\n",
    "            ax.scatter(\n",
    "                Rhp * np.cos(theta),\n",
    "                Rhp * np.sin(theta),\n",
    "                marker=\"*\",\n",
    "                color=\"green\",\n",
    "                s=30,\n",
    "                alpha=0.3,\n",
    "            )\n",
    "    return\n",
    "\n",
    "\n",
    "def find_failed_cells(df_bumps):\n",
    "    unique_failed_cells = set()\n",
    "    df = df_bumps.copy()\n",
    "    # Filter for columns starting with specific names\n",
    "    columns_of_interest = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if col.startswith(\"secondaryTest_Status_\")\n",
    "        or col.startswith(\"primaryTest_Status_\")\n",
    "    ]\n",
    "\n",
    "    for col in columns_of_interest:\n",
    "        if df[col].apply(lambda x: \"FAILED\" in str(x)).any():\n",
    "            # Find the first occurrence of \"FAILED\" in the column\n",
    "            failed_row = df[col][df[col].apply(lambda x: \"FAILED\" in str(x))].index[0]\n",
    "            unique_failed_cells.add((failed_row, col))\n",
    "\n",
    "    return unique_failed_cells\n",
    "\n",
    "\n",
    "# Find and print the first occurrence of \"FAILED\" in each column\n",
    "# failed_cells = find_failed_cells(df_bumps)\n",
    "# for index, col in failed_cells:\n",
    "#    print(f\"Failed '{col}'  Time Stamp: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58ae61-a375-48cc-b625-2ccdc6bf137a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating Histogram with failures\n",
    "\n",
    "Note that every actuator has a Z-axis, so we only show the orientatino of a given failure for dual axis actuator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8503c4-4db7-4df8-b71b-d64f0b088ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "plot_stacked_failures(ax, df_bumps, failures_to_show=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b69f59-7851-4c7a-8e94-eb938cdfc5ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Displaying Actuators Layout Highlingting Failures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a251b-446a-4807-b12c-f341d6b1beed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Getting sorted failures data frame\n",
    "failures_df = calculate_failures(df_bumps)\n",
    "\n",
    "# List of failed actuator IDs\n",
    "failures_df = failures_df[0:15]\n",
    "\n",
    "# Call the function to plot the actuators and flag the failed ones\n",
    "ActuatorsLayout(ax, failures_df, actuator_list=FATable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538c7d4-666a-4275-9e18-3c834a6622f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Histogram + Layout\n",
    "\n",
    "Same result as above, but putting both together with subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3cc89-9b78-4a00-961d-d02127c42864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of actuator with the highest falures to be shown\n",
    "failures_to_show = 15\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Histogram aspect should be automatic\n",
    "ax0.set_aspect(\"auto\", adjustable=\"box\")\n",
    "\n",
    "# Layout figre aspect needs to be rectangular\n",
    "ax1.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "# List of failed actuator IDs\n",
    "failures_df = failures_df[0:failures_to_show]\n",
    "\n",
    "# Call the function to plot the actuators and flag the failed ones\n",
    "plot_stacked_failures(ax0, df_bumps, failures_to_show=failures_to_show)\n",
    "\n",
    "# Call the function to plot the actuators and flag the failed ones\n",
    "ActuatorsLayout(ax1, failures_df, actuator_list=FATable)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"histogram_frequency_of_failures.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31efd47f-dcba-41de-b515-0635dbe7d723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T19:54:00.859301Z",
     "iopub.status.busy": "2023-08-30T19:54:00.858916Z",
     "iopub.status.idle": "2023-08-30T19:54:00.920880Z",
     "shell.execute_reply": "2023-08-30T19:54:00.920024Z",
     "shell.execute_reply.started": "2023-08-30T19:54:00.859274Z"
    },
    "tags": []
   },
   "source": [
    "## 3D Failures Rate Distribution\n",
    "---\n",
    "\n",
    "Here we want to create a 3d visualization of the failures\n",
    "\n",
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4d05d-f70a-4127-9e02-d283a472ff9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "\n",
    "def remove_zpanel(ax):\n",
    "    # Remove the z-axis panes, grids and lines\n",
    "    alpha = 0\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, alpha))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, alpha))\n",
    "    #\n",
    "    ax.zaxis._axinfo[\"grid\"][\"color\"] = (1.0, 1.0, 1.0, alpha)\n",
    "    ax.yaxis._axinfo[\"grid\"][\"linewidth\"] = 0\n",
    "    ax.xaxis._axinfo[\"grid\"][\"linewidth\"] = 0\n",
    "    #\n",
    "    ax.zaxis.line.set_lw(0.0)\n",
    "    ax.set_zticks([])\n",
    "    #\n",
    "    ax.set_zlabel(\"\")  # remove z-axis label 'z'\n",
    "\n",
    "\n",
    "def create_3d_heatmap(\n",
    "    ax, df_bumps, failures_df, actuator_list=FATable, failures_to_show=15\n",
    "):\n",
    "    # Failed actuators list\n",
    "    failed_actuators = [int(i) for i in list(failures_df.index)]\n",
    "\n",
    "    # Calculate failures\n",
    "    sorted_failed_counts_df = calculate_failures(df_bumps)\n",
    "    N = min(failures_to_show, len(sorted_failed_counts_df))\n",
    "\n",
    "    xpos, ypos = get_xy_position(actuator_list)\n",
    "\n",
    "    # Extract the number of tests\n",
    "    total_tests = sorted_failed_counts_df[\"TotalTests\"]\n",
    "\n",
    "    # Calculate the frequency of failures, individually\n",
    "    total_frequency = sorted_failed_counts_df[\"TotalFailures\"] / total_tests\n",
    "    pri_frequency = sorted_failed_counts_df[\"PrimaryFailures\"] / total_tests\n",
    "    sec_frequency = sorted_failed_counts_df[\"SecondaryFailures\"].fillna(0) / total_tests\n",
    "\n",
    "    # Calculate the radius of the cylinders based on the circle area\n",
    "    circle_area = 0.3  # Modify this value to adjust the cylinder size\n",
    "    circle_radius = np.sqrt(circle_area / np.pi)\n",
    "\n",
    "    ids = get_m1m3_actuator_ids()\n",
    "    xpos, ypos = get_xy_position(actuator_list)\n",
    "\n",
    "    table_xy_pos = id_position_map(actuator_list)\n",
    "\n",
    "    # Create the 3D bar plot for primary failures\n",
    "    for i in range(N):\n",
    "        actuator_id = sorted_failed_counts_df.index[i]\n",
    "        x = table_xy_pos[int(actuator_id)][0]\n",
    "        y = table_xy_pos[int(actuator_id)][1]\n",
    "        z = pri_frequency.loc[actuator_id]\n",
    "\n",
    "        ax.bar3d(\n",
    "            x - 0.15,\n",
    "            y - 0.15,\n",
    "            0,\n",
    "            circle_radius,\n",
    "            circle_radius,\n",
    "            z,\n",
    "            shade=True,\n",
    "            color=\"blue\",\n",
    "        )\n",
    "\n",
    "    # Create the 3D bar plot for secondary failures, stacked on top of primary failures\n",
    "    for i in range(N):\n",
    "        actuator_id = sorted_failed_counts_df.index[i]\n",
    "        x = table_xy_pos[int(actuator_id)][0]\n",
    "        y = table_xy_pos[int(actuator_id)][1]\n",
    "        z_bottom = pri_frequency.loc[actuator_id]\n",
    "        z = sec_frequency.loc[actuator_id]\n",
    "\n",
    "        ax.bar3d(\n",
    "            x - 0.15,\n",
    "            y - 0.15,\n",
    "            z_bottom,\n",
    "            circle_radius,\n",
    "            circle_radius,\n",
    "            z,\n",
    "            shade=True,\n",
    "            color=\"orange\",\n",
    "            label=\"Secondary\",\n",
    "        )\n",
    "\n",
    "        ax.text(\n",
    "            x,\n",
    "            y,\n",
    "            z + z_bottom + 0.01,\n",
    "            str(actuator_id),\n",
    "            color=\"black\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=\"xx-small\",\n",
    "        )\n",
    "\n",
    "        ax.view_init(elev=20.0, azim=218)\n",
    "\n",
    "    # Plot the actuators layout\n",
    "    ActuatorsLayout(ax, failures_df, actuator_list=FATable)\n",
    "\n",
    "    # Uncomment to remove z-panel from 3d plot.\n",
    "    # remove_zpanel(ax)\n",
    "\n",
    "    # Circles\n",
    "    ax.plot(xpos, ypos, \"o\", ms=14, color=\"blue\", alpha=0.05, mec=\"red\")\n",
    "\n",
    "    for l, x, y in zip(ids, xpos, ypos):\n",
    "        z = 0\n",
    "        ax.text(\n",
    "            x,\n",
    "            y,\n",
    "            z,\n",
    "            str(l),\n",
    "            color=\"black\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=\"xx-small\",\n",
    "        )\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c40389-fb43-40a4-b23d-94da17dd4200",
   "metadata": {},
   "source": [
    "### 3D Results\n",
    "\n",
    "Here we effectively show the failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e4c83-d7ce-439b-9302-724ce96cb946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create the figure and 3D Axes\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax_legend = fig.add_subplot(122)  # Legend subplot\n",
    "\n",
    "# Getting sorted failures data frame\n",
    "sorted_failed_counts_df = calculate_failures(df_bumps)\n",
    "\n",
    "# Total number of failed actuators to be shown\n",
    "failures_to_show = 15\n",
    "\n",
    "# Sliced data frame\n",
    "sorted_failed_df = sorted_failed_counts_df[0:failures_to_show]\n",
    "\n",
    "# Call the combined function to plot the 3D heatmap\n",
    "create_3d_heatmap(ax, df_bumps, sorted_failed_df, actuator_list=FATable)\n",
    "\n",
    "\n",
    "# Create a custom legend for the legend subplot\n",
    "legend_patches = [\n",
    "    Patch(color=\"blue\", label=\"Primary Failures\"),\n",
    "    Patch(color=\"orange\", label=\"Secondary Failures\"),\n",
    "]\n",
    "\n",
    "ax_legend.legend(handles=legend_patches, loc=\"best\")\n",
    "ax_legend.axis(\"off\")  # Turn off the axes for the legend subplot\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save fig\n",
    "# plt.savefig(\"layout_frequency_of_failures.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
