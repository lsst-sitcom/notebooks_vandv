{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72cef637-a558-4af8-99ad-fd87380468dd",
   "metadata": {},
   "source": [
    "# SITCOM-1399: Adding Earthquake events to the TN81, on vibration on M1M3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccba396-fc91-4462-8622-0a8665e43ef1",
   "metadata": {},
   "source": [
    "**DescripciÃ³n**\n",
    "\n",
    "Sub-ticket related to the [SITCOM-918: Write technote on hardpoint oscillations during tma slews](https://rubinobs.atlassian.net/browse/SITCOM-918), to study earthquake events seen by M1M3. \n",
    "We can read the TN81 [here](https://sitcomtn-081.lsst.io/v/SITCOM-918/index.html).\n",
    "\n",
    "See more about the ticket in: [https://rubinobs.atlassian.net/browse/SITCOM-1399](https://rubinobs.atlassian.net/browse/SITCOM-1399)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f28fd-ef4a-4fa4-a5ab-73a757959977",
   "metadata": {},
   "source": [
    "**More information**\n",
    "\n",
    "The **VMS (Vibration Monitoring System)** is a set of accelerometers mounted on the M1M3, M2, and Camera Rotator that measure high frequency accelerations (not including gravity). The data rate is 200 hz, and so can be used to identify vibrations up to 100 hz. More information can be found [confluence](https://confluence.lsstcorp.org/x/jQhUCQ). There are multiple sensors on each of the three components. In particular, for M1M3 has 3 sensors.\n",
    "\n",
    "The VMS data for the mag~6 earthquake of September are shown in slides no. 56 and 57 available [here](https://docs.google.com/presentation/d/1HmmzIUt0XszK0XMS1YZtQiYCvdwajhrZ8p3ZdAVSp14/edit#slide=id.g2633a5ccbdd_1_394).\n",
    "\n",
    "In this notebook we will study whether this type of event is safe for the mirror.\n",
    "\n",
    "The dates of large earthquakes are:\n",
    "- 2023-09-06 23:48:15 UTC\n",
    "- 2023-10-31 12:33:43 UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca43c3-0c39-42fa-95b4-82100be4937a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T15:47:36.513702Z",
     "iopub.status.busy": "2024-06-12T15:47:36.513386Z",
     "iopub.status.idle": "2024-06-12T15:47:36.515840Z",
     "shell.execute_reply": "2024-06-12T15:47:36.515467Z",
     "shell.execute_reply.started": "2024-06-12T15:47:36.513688Z"
    }
   },
   "source": [
    "## Function the read VMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb9bbe64-0eac-4125-9469-2d5c6be88201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T11:58:10.474522Z",
     "iopub.status.busy": "2024-06-13T11:58:10.474238Z",
     "iopub.status.idle": "2024-06-13T11:58:10.526661Z",
     "shell.execute_reply": "2024-06-13T11:58:10.526362Z",
     "shell.execute_reply.started": "2024-06-13T11:58:10.474510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, time, os, asyncio\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import signal\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "from lsst.summit.utils.tmaUtils import TMAEventMaker, TMAState\n",
    "from lsst.summit.utils.efdUtils import getEfdData, makeEfdClient, clipDataToEvent, calcNextDay\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf0c802-0745-4a76-9250-9740c3118c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T11:58:13.207934Z",
     "iopub.status.busy": "2024-06-13T11:58:13.207541Z",
     "iopub.status.idle": "2024-06-13T11:58:13.249245Z",
     "shell.execute_reply": "2024-06-13T11:58:13.248943Z",
     "shell.execute_reply.started": "2024-06-13T11:58:13.207922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to get data\n",
    "# Modified functions of ticket SITCOM-761\n",
    "\n",
    "key_m1m3_dict={'1 X': 'm1m3_x_1', \n",
    "            '1 Y': 'm1m3_y_1', \n",
    "            '1 Z': 'm1m3_z_1', \n",
    "            '2 X': 'm1m3_x_2', \n",
    "            '2 Y': 'm1m3_z_2', # note these two have been \n",
    "            '2 Z': 'm1m3_y_2', # switched pending SUMMIT-7911\n",
    "            '3 X': 'm1m3_x_3', \n",
    "            '3 Y': 'm1m3_y_3', \n",
    "            '3 Z': 'm1m3_z_3'\n",
    "            }\n",
    "\n",
    "def vms_data_to_pandas(filename, vms_type, begin_time=None, end_time=None):\n",
    "    \"\"\"\n",
    "    Converts VMS data in the given HDF5 file to a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "    filename: Path to the HDF5 file containing the VMS data.\n",
    "    vms_type: The type of VMS data in the file. Must be \"m1m3\", \"m2\", or\n",
    "      \"rotator\".\n",
    "    begin_time: The start time of the data to include in the DataFrame. If None,\n",
    "      all data will be included.\n",
    "    end_time: The end time of the data to include in the DataFrame. If None, all\n",
    "      data will be included.\n",
    "\n",
    "    Returns:\n",
    "    A Pandas DataFrame containing the VMS data.\n",
    "    \"\"\"\n",
    "    if vms_type == \"m1m3\":\n",
    "        key_dict=key_m1m3_dict\n",
    "    #elif vms_type==\"m2\":\n",
    "    #    key_dict=key_m2_dict\n",
    "    #elif vms_type==\"rotator\":\n",
    "    #    raise NotImplementedError\n",
    "    else:\n",
    "        raise ValueError('vms_type must be m1m3,m2, or rotator')\n",
    "\n",
    "    f = h5py.File(filename, 'r')\n",
    "    times = f['timestamp'][::1]\n",
    "    dkeys = 'XYZ'\n",
    "   \n",
    "    data_dict = {}\n",
    "    if (begin_time is not None) & (end_time is not None): \n",
    "        sel = (times > begin_time) & (times < end_time)\n",
    "    else: \n",
    "        sel = np.ones(times.size).astype(bool)\n",
    "    data_dict['times'] = times[sel]  \n",
    "    for key in key_dict.keys():\n",
    "        data_dict[key_dict[key]] = f[key][::1][sel]\n",
    "    data_frame = pd.DataFrame(data_dict)\n",
    "    for j in np.arange(int(len(key_dict)/3)) +1:\n",
    "        data_frame[f\"total_{j}\"] = np.linalg.norm(\n",
    "            data_frame[[f\"{vms_type}_{i}_{j}\" for i in [\"x\",\"y\",\"z\"]]].values, axis=1\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def get_efd_data(begin, end, client):\n",
    "\n",
    "    \"\"\"Extract all the MTMount data from the EFD and add to dict.\n",
    "\n",
    "    Args:\n",
    "        begin (str): The start time of the query.\n",
    "        end (str): The end time of the query.\n",
    "        client (object): influx client\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the MTMount data.\n",
    "    \"\"\"\n",
    "\n",
    "    query_dict = {}\n",
    "\n",
    "    query_dict[\"el\"] = getEfdData(\n",
    "        client,\n",
    "        \"lsst.sal.MTMount.elevation\",\n",
    "        columns=[\"private_sndStamp\", \"private_efdStamp\", \"actualPosition\", \"actualVelocity\", \"actualTorque\"],\n",
    "        begin=begin,\n",
    "        end=end,\n",
    "        prePadding=0,\n",
    "        postPadding=0,\n",
    "        warn=False,\n",
    "    )\n",
    "    query_dict[\"az\"] = getEfdData(\n",
    "        client,\n",
    "        \"lsst.sal.MTMount.azimuth\",\n",
    "        columns=[\"private_sndStamp\", \"private_efdStamp\", \"actualPosition\", \"actualVelocity\", \"actualTorque\"],\n",
    "        begin=begin,\n",
    "        end=end,\n",
    "        prePadding=0,\n",
    "        postPadding=0,\n",
    "        warn=False,\n",
    "    )\n",
    "    return query_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f9c19e-ec3e-4314-8c47-865bc24acb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T12:28:20.586809Z",
     "iopub.status.busy": "2024-06-13T12:28:20.586262Z",
     "iopub.status.idle": "2024-06-13T12:28:20.635198Z",
     "shell.execute_reply": "2024-06-13T12:28:20.634890Z",
     "shell.execute_reply.started": "2024-06-13T12:28:20.586797Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_freq_psd(vals, timestep):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the frequency power spectrum of a signal.\n",
    "\n",
    "    Args:\n",
    "        vals (np.array): The signal values.\n",
    "        timestep (float): The time step between samples.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The frequencies and power spectral density.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove the mean from the signal.\n",
    "    meanval = np.mean(vals)\n",
    "    signal = vals - meanval\n",
    "\n",
    "    # Calculate the length of the signal.\n",
    "    N = len(signal)\n",
    "\n",
    "    # Calculate the power spectral density.\n",
    "    psd = np.abs(np.fft.rfft(np.array(signal) * 1)) ** 2\n",
    "\n",
    "    # Calculate the frequencies.\n",
    "    frequencies = np.fft.rfftfreq(N, timestep)\n",
    "\n",
    "    return (frequencies, psd)\n",
    "\n",
    "def get_peak_points(freq, psd, height=0.01):\n",
    "    \"\"\"\n",
    "    Get the peak points of the power spectral density (PSD).\n",
    "\n",
    "    Args:\n",
    "        freq (numpy.ndarray): The frequency vector.\n",
    "        psd (numpy.ndarray): The power spectral density.\n",
    "        height (float): The minimum peak height.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The peak points.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the peak indices and heights.\n",
    "    peak_ind, peak_dict = find_peaks(psd, height=height)\n",
    "    peaks = freq[peak_ind]\n",
    "\n",
    "    # If there are no peaks, return None.\n",
    "    if len(peaks) < 1:\n",
    "        return None\n",
    "\n",
    "    # Find the sub-peaks within each group of peaks that are close in frequency.\n",
    "    points = []\n",
    "    for i, peak in enumerate(peaks):\n",
    "        sel = (abs(peaks - peak) < 1)\n",
    "        sub_peaks = peaks[sel]\n",
    "        sub_heights = peak_dict['peak_heights'][sel]\n",
    "        points.append(sub_peaks[np.argmax(sub_heights)])\n",
    "\n",
    "    # Return the unique peak points.\n",
    "    return np.unique(np.array(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f0bbb-ed43-440f-b5f1-e36b07843238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
