{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c30bfe-0ecc-45ad-977b-eff34fa3fdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import sys, time, os, asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from lsst_efd_client import EfdClient\n",
    "from lsst.summit.utils.efdUtils import makeEfdClient, calcNextDay, getEfdData\n",
    "from lsst.summit.utils.tmaUtils import TMAEventMaker, TMAState\n",
    "import lsst.sitcom.vandv.m1m3.sitcomtn81.sitcomtn_81_identify_oscillations as sitcomtn81\n",
    "\n",
    "\n",
    "summit_utils_logger = logging.getLogger(\"lsst.summit.utils\")\n",
    "summit_utils_logger.setLevel(logging.ERROR)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a3dd1-3a9c-48b6-b042-8997384e9bf3",
   "metadata": {},
   "source": [
    "# This runs the script to identify times during tma slews with oscillations in the measured hardpoints\n",
    "\n",
    "1. Identify days that contain slews\n",
    "2. For each day with a slew run the identification script\n",
    "3. For each day create diagnostic plot to visually inspect identified events\n",
    "4. Save visually inspected events\n",
    "5. Create Chronograph links for events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c629c4-a478-4255-9233-cf0c8abef2ee",
   "metadata": {},
   "source": [
    "## 1. identify days with slews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b92ca-c3b0-40b5-8a5e-1e9ba89b72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for days that have no eventMaker problems and have slews\n",
    "day_start = 20231204\n",
    "day_end = 20240115\n",
    "day_range = []\n",
    "eventMaker = TMAEventMaker()\n",
    "client = eventMaker.client\n",
    "\n",
    "\n",
    "while day_start <= day_end:\n",
    "    day_obs = day_start\n",
    "    try:\n",
    "        events = eventMaker.getEvents(day_obs)\n",
    "    except RuntimeError as error:\n",
    "        print(f\"{day_obs} Caught an error: {error}\")\n",
    "        day_start = calcNextDay(day_start)\n",
    "        continue\n",
    "\n",
    "    slews = [e for e in events if e.type == TMAState.SLEWING]\n",
    "    try:\n",
    "        print(f\"{day_obs} - {len(slews)} slews\")\n",
    "        if len(slews) > 0:\n",
    "            day_range.append(day_start)\n",
    "    except:\n",
    "        print(f\"problem with {day_obs}\")\n",
    "\n",
    "    day_start = calcNextDay(day_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66223b56-b0e9-4f62-8f75-e02e03c663d1",
   "metadata": {},
   "source": [
    "## 2. for each day with a slew run the identification script\n",
    "this script is `sitcomtn81.IdentifyOscillationEvents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8f60c-6457-4f56-8c52-234887f24f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapath = \"./sitcomtn81_data\"\n",
    "force = False\n",
    "efd_instance = \"usdf_efd\"\n",
    "if not os.path.exists(datapath):\n",
    "    os.makedirs(datapath)\n",
    "\n",
    "id_oscillations = sitcomtn81.IdentifyOscillationEvents(efd_instance=efd_instance)\n",
    "\n",
    "for current_day_obs in day_range:\n",
    "    print(current_day_obs)\n",
    "    save_string = f\"{datapath}/oscillation_events_{current_day_obs}.csv\"\n",
    "    if os.path.exists(save_string):\n",
    "        print(f\"file exists: {save_string}\")\n",
    "        continue\n",
    "    oscillation_events_frame = await id_oscillations.run(current_day_obs)\n",
    "    if oscillation_events_frame is not None:\n",
    "        oscillation_events_frame.to_csv(save_string)\n",
    "        print(\"finished\")\n",
    "    else:\n",
    "        print(\"none identified\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9ab9a-9ccf-425e-99c9-d626abf1a973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_timestamp(data):\n",
    "    \"\"\"\n",
    "    Adds a correct timestamp column in UTC format to the provided data if\n",
    "    not present.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        The data to which the timestamp will be added.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The data with the added 'snd_timestamp_utc' column.\n",
    "    \"\"\"\n",
    "    if \"snd_timestamp_utc\" not in data.columns:\n",
    "        data[\"snd_timestamp_utc\"] = Time(\n",
    "            data[\"private_sndStamp\"], format=\"unix_tai\"\n",
    "        ).unix\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(events_frame, client, train=False):\n",
    "    table_dict = {\n",
    "        \"m1m3_hp_actuator\": \"lsst.sal.MTM1M3.hardpointActuatorData\",\n",
    "    }\n",
    "    query_dict = {}\n",
    "    for key in table_dict.keys():\n",
    "        query_dict[key] = []\n",
    "    for j, time in tqdm(enumerate(events_frame[\"times\"])):\n",
    "        event_time = Time(events_frame[\"times\"][j] - 2, format=\"unix\")\n",
    "\n",
    "        for key in table_dict.keys():\n",
    "            hpcols = [\"private_sndStamp\"] + [f\"measuredForce2\"]  # for i in range(6)]\n",
    "            query = getEfdData(\n",
    "                client=client,\n",
    "                topic=table_dict[key],\n",
    "                columns=hpcols,\n",
    "                begin=event_time,\n",
    "                end=event_time,\n",
    "                prePadding=60,\n",
    "                postPadding=60,\n",
    "            )\n",
    "            query[\"event_num\"] = j\n",
    "            query[\"seqNum\"] = events_frame[\"seq_num\"][j]\n",
    "\n",
    "            query = add_timestamp(query)\n",
    "\n",
    "            query_dict[key].append(query)\n",
    "    \n",
    "    # Iterate over the remaining DataFrames and merge them\n",
    "    for key in sorted_keys[1:]:\n",
    "        merged_df = pd.merge_asof(\n",
    "            merged_df,\n",
    "            query_dict[key].sort_index(),\n",
    "            left_on=\"snd_timestamp_utc\",\n",
    "            right_on=\"snd_timestamp_utc\",\n",
    "            tolerance=tolerance,\n",
    "            direction=\"nearest\",\n",
    "            suffixes=(\"\", \"_\" + key),\n",
    "        )\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1fd965-087c-4eef-b9dc-1994656926d3",
   "metadata": {},
   "source": [
    "## 3. For each day create diagnostic plot to visually inspect identified events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650bbde-fe22-43a0-a6f3-cecbf68a6ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = EfdClient(\"usdf_efd\")\n",
    "from glob import glob\n",
    "\n",
    "flist = glob(\"./sitcomtn81_data/oscillation_events_*.csv\")\n",
    "days_with_events = []\n",
    "for file in flist:\n",
    "    dat = pd.read_csv(file)\n",
    "    if len(dat) > 0:\n",
    "        days_with_events.append(file[-12:-4])\n",
    "days_with_events = sorted(days_with_events)\n",
    "print(f\"{len(days_with_events)} days with an event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b02dee-fd14-4646-a00b-dda499a7d033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "days_with_events = [i for i in days_with_events if float(i) > 20231204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b1f86-3271-498c-a4ca-972678dd96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(days_with_events):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4afdd4-f48a-40b8-af77-8d651b55d50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select day from above list starting with 0 then run next 5 cells then increment this index\n",
    "index = 17\n",
    "day = days_with_events[index]\n",
    "eventMaker = TMAEventMaker()\n",
    "events = eventMaker.getEvents(int(day))\n",
    "\n",
    "events_frame = pd.read_csv(f\"./sitcomtn81_data/oscillation_events_{day}.csv\")\n",
    "print(indexer, day, len(events_frame))\n",
    "if len(events_frame) > 1000:\n",
    "    sep_sel = [True] + list((np.diff(events_frame[\"times\"]) > 8))\n",
    "    print(len(events_frame[sep_sel]))\n",
    "    events_frame = events_frame[sep_sel].reset_index()\n",
    "merged_df = get_data(events_frame, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba02f66-52e8-4d98-bd5e-936cfcd9af5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for m in range(int(len(events_frame) / 120) + 1):\n",
    "    l = 4  # should be 1 or 4\n",
    "    plt.figure(dpi=175, figsize=(12, 8 * l))\n",
    "    j = 0\n",
    "    k = 30 * l * m\n",
    "    for i in np.unique(merged_df[\"event_num\"])[k : k + 30 * l]:\n",
    "        # if i not in good:\n",
    "        #     continue\n",
    "        plt.title(f\"{day}, {k}, {l}, {k/l/30}\")\n",
    "        subframe = merged_df.copy()\n",
    "        subframe = subframe[subframe[\"event_num\"] == i]\n",
    "        seq_val = np.unique(subframe[\"seqNum\"])\n",
    "        if len(subframe) > 0:\n",
    "            plt.plot(\n",
    "                subframe[\"delta_time\"],\n",
    "                subframe[\"measuredForce2\"] - 800 * j,\n",
    "                label=f\"{seq_val[0]}, {i}\",\n",
    "            )\n",
    "            plt.annotate(xy=(-20, -800 * j + 10), text=f\"{seq_val[0]}, {i}\")\n",
    "            j += 1\n",
    "\n",
    "    if l == 1:\n",
    "        plt.legend()\n",
    "    if l == 4:\n",
    "        plt.legend(fontsize=9.2, loc=7, title=\"seqNum, eventNum\")\n",
    "    plt.axvline(2, c=\"k\", ls=\"dashed\")\n",
    "    plt.savefig(f\"./sitcomtn81_data/plots/diagnostic_{day}_{k}_{l}_{int(k/l/30)}.png\")\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d78620-56de-4214-abcb-4450964c1258",
   "metadata": {},
   "source": [
    "## 4. Save visually inspected events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ded02e-e64c-4f1b-9657-f8f7b28300cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after inspecting the above plots\n",
    "cleaned_event_nums = [572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e78df-9683-40b7-882c-f8342ae0d7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = 1\n",
    "plt.figure(dpi=175, figsize=(10, 8 * l))\n",
    "j = 0\n",
    "k = 30 * l * m\n",
    "offset = 2000\n",
    "for i in np.unique(merged_df[\"event_num\"]):  # [k : k + 30 * l]:\n",
    "    if i not in cleaned_event_nums:\n",
    "        continue\n",
    "    plt.title(f\"{day} slews with oscillations\")\n",
    "    subframe = merged_df.copy()\n",
    "    subframe = subframe[subframe[\"event_num\"] == i]\n",
    "    seq_val = np.unique(subframe[\"seqNum\"])\n",
    "    # block_num = np.unique(subframe[\"block\"])\n",
    "    if len(subframe) > 0:\n",
    "        plt.plot(\n",
    "            subframe[\"delta_time\"],  # - offset_dict[i],\n",
    "            subframe[\"measuredForce2\"]\n",
    "            - subframe[\"measuredForce2\"][subframe[\"delta_time\"] < 0].mean()\n",
    "            - offset * j,\n",
    "            label=f\"{seq_val[0]}\",\n",
    "        )\n",
    "        j += 1\n",
    "if l == 1:\n",
    "    plt.legend(title=\"slew number\")\n",
    "if l == 4:\n",
    "    plt.legend(fontsize=9.2, loc=7)\n",
    "# plt.axvline(0, c=\"k\", ls=\"dashed\")\n",
    "plt.ylabel(f\"$\\Delta$ HP 2 force [N] - {offset} N offset\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.xlim(-10, 25)\n",
    "plt.axvline(0, ls=\"dashed\", c=\"k\")\n",
    "plt.savefig(f\"./sitcomtn81_data/plots/osc_hp2_{day}.png\")\n",
    "\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56037911-95c9-4a66-ba6b-3e1666999437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_list = []\n",
    "for row in cleaned_event_nums:\n",
    "    day_obs, seq_num, times = events_frame.loc[row, [\"day_obs\", \"seq_num\", \"times\"]]\n",
    "    print(f\"{day_obs}, {seq_num}, {row}, {times}\")\n",
    "    seq_list.append(row)\n",
    "events_frame.loc[seq_list, [\"day_obs\", \"seq_num\", \"times\"]].to_csv(\n",
    "    f\"{datapath}/cleaned_events{day}.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914abd8-8e6e-4940-91aa-3bc12ecdfada",
   "metadata": {},
   "source": [
    "After visually inspecting all events, the combined cleaned csv is attached to jira ticket called 231114_cleaned_oscillations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c5a9e-1473-4f36-9c58-9aa705578451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_frame = []\n",
    "for day in days_with_events:\n",
    "    try:\n",
    "        df = pd.read_csv(f\"./sitcomtn81_data/cleaned_events{day}.csv\")\n",
    "        df.columns = [\"day_obs\", \"seq_num\", \"time\"]\n",
    "        clean_frame.append()\n",
    "    except:\n",
    "        a = 2\n",
    "osc_frame_1 = pd.read_csv(\n",
    "    f\"./sitcomtn81_data/231121_dynamic_testing_cleaned_oscillations.csv\"\n",
    ")\n",
    "osc_frame_1 = osc_frame_1.drop(\"osc_event_num\", axis=1)\n",
    "clean_frame.append(osc_frame_1)\n",
    "\n",
    "osc_frame_2 = pd.read_csv(f\"./sitcomtn81_data/231114_cleaned_oscillations.csv\")\n",
    "osc_frame_2 = osc_frame_2.drop(\" osc_event_num\", axis=1)\n",
    "osc_frame_2.columns = [\"day_obs\", \"seq_num\", \"time\"]\n",
    "clean_frame.append(osc_frame_2)\n",
    "\n",
    "oscillation_frame = (\n",
    "    pd.concat(clean_frame).sort_values(by=\"day_obs\").reset_index(drop=True)\n",
    ")\n",
    "\n",
    "oscillation_frame.to_csv(\n",
    "    \"./sitcomtn81_data/240327_dynamic_testing_hp_osc_events.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d6135-f9a6-41eb-903f-e19096766d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_frame = []\n",
    "for file in flist:\n",
    "    dat = pd.read_csv(file)\n",
    "    all_frame.append(dat)\n",
    "all_frame = pd.concat(all_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fdc32-08f5-409d-8f09-f6479c32cbd0",
   "metadata": {},
   "source": [
    "## 5. Create Chronograph links for the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab2885-bd52-4e0f-bc34-e54f475a8929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_frame = (\n",
    "    pd.merge(all_frame, clean_frame, left_on=\"times\", right_on=\"time\", how=\"inner\")\n",
    "    .drop_duplicates(subset=\"time\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "events_frame[\"iso_time\"] = Time(events_frame[\"times\"], format=\"unix\").iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1dca5-7d08-45c5-993a-0d27c9066734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_frame = events_frame.sort_values(\"times\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3caaa-97f9-45c2-921c-e95406b59acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08903f-66f5-4269-be3c-a571f3080a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def link_from_date(timestamp):\n",
    "    begin_timestamp = (Time(timestamp, format=\"unix\") - TimeDelta(3, format=\"sec\")).iso\n",
    "    end_timestamp = (Time(timestamp, format=\"unix\") + TimeDelta(3, format=\"sec\")).iso\n",
    "\n",
    "    begin_day = begin_timestamp[:10]\n",
    "    begin_hour = begin_timestamp[11:13]\n",
    "    begin_minute = begin_timestamp[14:16]\n",
    "    begin_second = begin_timestamp[17:]\n",
    "\n",
    "    end_day = end_timestamp[:10]\n",
    "    end_hour = end_timestamp[11:13]\n",
    "    end_minute = end_timestamp[14:16]\n",
    "    end_second = end_timestamp[17:]\n",
    "\n",
    "    url = \"https://summit-lsp.lsst.codes/chronograf/sources/1/dashboards/\"\n",
    "    url += \"207?refresh=Paused&tempVars%5BDownsample%5D=Default&tempVars%5BFunction%5D=\"\n",
    "    url += f\"raw&lower={begin_day}T{begin_hour}%3A{begin_minute}%3A{begin_second}Z\"\n",
    "    url += f\"&upper={end_day}T{end_hour}%3A{end_minute}%3A{end_second}Z\"\n",
    "    # url+=f\"&zoomedLower={begin_day}T{begin_hour}%3A{begin_minute}%3A{begin_second}Z&zoomedUpper=2023-05-30T10%3A08%3A02.962Z\"\n",
    "    return url\n",
    "\n",
    "\n",
    "title_str = \"| event number  | time  |  dayobs | slew_num |  elevation |  elevation max velocity| azimuth max velocity | hardpoint/ims dashboard  |\"\n",
    "title_str += \"\\n|---|---|---|---|---|---|---|---|\\n\"\n",
    "# create html table for confluence\n",
    "row_str = \"\"\n",
    "ct = 0\n",
    "for j, i in enumerate((range(len(events_frame)))):\n",
    "    # if events[\"group\"][i] < 3:\n",
    "    ct += 1\n",
    "    row_str += f\"| {ct}  | {events_frame['iso_time'][i]}  | \"\n",
    "    row_str += f\"{events_frame['day_obs_x'][i]} | {events_frame['seq_num_x'][i]} |\"\n",
    "    row_str += f\"{events_frame['elevation_position'][i]:0.2f}  | {events_frame['elevation_velocity'][i]:0.2f} | \"\n",
    "    row_str += f\" {events_frame['azimuth_velocity'][i]:0.2f} \"\n",
    "    row_str += '| <a href=\"'\n",
    "    row_str += f'{link_from_date(events_frame[\"times\"][i]+3)}'\n",
    "    row_str += '\" target=\"_blank\">link to dashboard</a>|\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c09ad-c1eb-4f04-b4dd-336f35ba2a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(title_str + row_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09baee68-1c37-4c90-a016-fd922c39356f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
