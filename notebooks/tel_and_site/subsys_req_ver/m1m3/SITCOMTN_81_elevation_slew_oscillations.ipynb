{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9170c2-2884-4717-b27b-5809d14e744c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, time, os, asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from lsst_efd_client import EfdClient\n",
    "from lsst.summit.utils.efdUtils import makeEfdClient, getEfdData\n",
    "from lsst.summit.utils.tmaUtils import TMAEventMaker, TMAState\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab5d01-7e0b-4ffb-844d-d16b784290ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_timestamp(data):\n",
    "    \"\"\"\n",
    "    Adds a correct timestamp column in UTC format to the provided data if\n",
    "    not present.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        The data to which the timestamp will be added.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The data with the added 'snd_timestamp_utc' column.\n",
    "    \"\"\"\n",
    "    if \"snd_timestamp_utc\" not in data.columns:\n",
    "        data[\"snd_timestamp_utc\"] = Time(\n",
    "            data[\"private_sndStamp\"], format=\"unix_tai\"\n",
    "        ).unix\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(events_frame, client_usdf, client_idf, train=False):\n",
    "    table_dict = {\n",
    "        \"m1m3_hp_actuator\": \"lsst.sal.MTM1M3.hardpointActuatorData\",\n",
    "        # \"m1m3_hp_monitor\": \"lsst.sal.MTM1M3.hardpointMonitorData\",\n",
    "        # \"mtmount_elevation\": \"lsst.sal.MTMount.elevation\",\n",
    "        # \"mtmount_azimuth\": \"lsst.sal.MTMount.azimuth\",\n",
    "        # \"m1m3_ims\": \"lsst.sal.MTM1M3.imsData\"\n",
    "    }\n",
    "    query_dict = {}\n",
    "    for key in table_dict.keys():\n",
    "        query_dict[key] = []\n",
    "    for j, time in tqdm(enumerate(events_frame[\"time\"])):\n",
    "        event_time = Time(events_frame[\"time\"][j], format=\"unix\")\n",
    "        if event_time < datetime(2023, 11, 28):\n",
    "            client = client_idf\n",
    "        else:\n",
    "            client = client_usdf\n",
    "        # slew = eventMaker.findEvent(Time(events_frame[\"time\"][j], format=\"unix\"))\n",
    "        # if slew.blockInfos is None:\n",
    "        #     block = None\n",
    "        # else:\n",
    "        # block = slew.blockInfos.blockNumber\n",
    "\n",
    "        for key in table_dict.keys():\n",
    "            query_list = []\n",
    "            for col in [\"private_sndStamp\"] + [f\"measuredForce{i}\" for i in range(6)]:\n",
    "                hpcols = [col]\n",
    "                query_list.append(\n",
    "                    getEfdData(\n",
    "                        client=client,\n",
    "                        topic=table_dict[key],\n",
    "                        columns=hpcols,\n",
    "                        begin=event_time,\n",
    "                        end=event_time,\n",
    "                        prePadding=10,\n",
    "                        postPadding=10,\n",
    "                    )\n",
    "                )\n",
    "            query = pd.concat(query_list, axis=1)\n",
    "            if len(query) == 0:\n",
    "                continue\n",
    "            query[\"event_num\"] = j\n",
    "            query[\"seqNum\"] = events_frame[\"seq_num\"][j]\n",
    "            query[\"event_time\"] = events_frame[\"time\"][j]\n",
    "            query = add_timestamp(query)\n",
    "\n",
    "            # query[\"block\"] = block\n",
    "            query[\"oscillation_bool\"] = 0\n",
    "            query[\"delta_time\"] = query[\"snd_timestamp_utc\"] - events_frame[\"time\"][j]\n",
    "\n",
    "            query_dict[key].append(query)\n",
    "    for key in table_dict.keys():\n",
    "        query_dict[key] = pd.concat(query_dict[key])\n",
    "    sorted_keys = sorted(query_dict.keys())\n",
    "    initial_key = sorted_keys[0]\n",
    "    merged_df = query_dict[initial_key].sort_index()\n",
    "    # Define your tolerance for matching\n",
    "    tolerance = 0.03  # pd.Timedelta('0.03 seconds')\n",
    "\n",
    "    # Iterate over the remaining DataFrames and merge them\n",
    "    for key in sorted_keys[1:]:\n",
    "        merged_df = pd.merge_asof(\n",
    "            merged_df,\n",
    "            query_dict[key].sort_index(),\n",
    "            left_on=\"snd_timestamp_utc\",\n",
    "            right_on=\"snd_timestamp_utc\",\n",
    "            tolerance=tolerance,\n",
    "            direction=\"nearest\",\n",
    "            suffixes=(\"\", \"_\" + key),\n",
    "        )\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ecb6c-1722-409b-8db5-b2faaa649cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stats(data):\n",
    "    keys = [f\"measuredForce{n}\" for n in range(5)]\n",
    "    max_val = np.max(data[key])\n",
    "    min_val = np.min(data[key])\n",
    "    ptp = np.ptp(data[key])\n",
    "    before_std = np.std(data.loc[(data[\"delta_time\"].values < 0), key])\n",
    "    rolling_std = data[\"measuredForce2\"].rolling(100).std()\n",
    "    max_time = data.iloc[np.argmax(data[key]), :][\"delta_time\"]\n",
    "    sel_time = (data[\"delta_time\"] > max_time) & (rolling_std <= before_std + 10)\n",
    "\n",
    "    if sel_time.sum() > 0:\n",
    "        duration = np.min(data.loc[sel_time, \"delta_time\"].values)\n",
    "        return max_val, min_val, ptp, duration\n",
    "    else:\n",
    "        return max_val, min_val, ptp\n",
    "\n",
    "\n",
    "def get_stats(data):\n",
    "    # Create an empty DataFrame to store the results\n",
    "    stats_df = pd.DataFrame(\n",
    "        columns=[\"name\", \"Max Value\", \"Min Value\", \"Peak-to-Peak\", \"Duration\"]\n",
    "    )\n",
    "\n",
    "    # Define the keys\n",
    "    keys = [f\"measuredForce{n}\" for n in range(6)]\n",
    "    rows = []\n",
    "    for key in keys:\n",
    "        sel_0 = data[\"delta_time\"] > 0\n",
    "        max_val = max(data.loc[sel_0, key], key=abs)\n",
    "        # min_val = np.min(data.loc[sel_0, key])\n",
    "        ptp = np.ptp(data.loc[sel_0, key])\n",
    "        before_std = np.std(data.loc[(data[\"delta_time\"].values < 0), key])\n",
    "        before_mean = np.mean(data.loc[(data[\"delta_time\"].values < 0), key])\n",
    "        rolling_std = data[key].rolling(100).std()\n",
    "        max_time = data.iloc[np.argmax(data[key]), :][\"delta_time\"]\n",
    "        sel_time = (\n",
    "            (data[\"delta_time\"] > max_time) & (rolling_std <= before_std * 2) & sel_0\n",
    "        )\n",
    "\n",
    "        # Calculate duration if condition is met\n",
    "        if sel_time.sum() > 0:\n",
    "            duration = np.min(data.loc[sel_time, \"delta_time\"].values)\n",
    "        else:\n",
    "            duration = np.nan  # Use NaN for cases where the condition is not met\n",
    "\n",
    "        # Create a row dictionary and append to the list\n",
    "        row = {\n",
    "            \"key\": key,\n",
    "            \"max\": max_val,\n",
    "            \"mean\": before_mean,\n",
    "            \"ptp\": ptp,\n",
    "            \"duration\": duration,\n",
    "        }\n",
    "        rows.append(row)\n",
    "    stats_df = pd.DataFrame(rows)\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaeb75-39fd-4c57-9c49-01f276e01d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81387b6e-7b9c-4be0-84d4-9f2b25028840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_usdf = EfdClient(\"usdf_efd\")\n",
    "client_idf = EfdClient(\"idf_efd\")\n",
    "events_frame = pd.read_csv(\n",
    "    \"./sitcomtn81_data/231121_dynamic_testing_cleaned_oscillations.csv\"\n",
    ")\n",
    "dayObs = 20231205\n",
    "events_frame = events_frame  # [events_frame[\"day_obs\"] == dayObs].reset_index()\n",
    "merged_df = get_data(events_frame, client_usdf, client_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccab51a-cf86-4625-af5f-4e80062f8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keep_bool = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "keep_bool += [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "keep_bool += [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "keep_bool += [0, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
    "\n",
    "keep_bool += [1, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "keep_bool += [1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "keep_bool += [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "keep_bool += [0, 1, 1, 0, 1]\n",
    "keep_bool = keep_bool + list(np.ones(len(events_frame) - len(keep_bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557c190-774f-4a87-9031-ecacf81c5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_frame[\"event_num\"] = np.arange(len(events_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5573a-7771-4ba0-a1aa-2954f524d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_events_frame = events_frame[np.array(keep_bool) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a4b89-1e25-438f-9bfd-9b3876a84d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [-0.1, -1.5, -4, 1, 6, -2, -2, -1.5, 4.5, -2, -2]\n",
    "offsets += [-2, -2]\n",
    "real_events_frame.loc[:, \"offset\"] = offsets + list(\n",
    "    np.zeros(len(real_events_frame) - len(offsets))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed20476-a55f-4368-a35a-a103461fd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_events_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cc11f-b783-45aa-ba61-53dbf6705eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 4  # should be 1 or 4\n",
    "plt.figure(dpi=175, figsize=(12, 8))\n",
    "for i in real_events_frame[\"event_num\"]:\n",
    "    # plt.title(f\"{day}, {k}, {l}, {k/l/30}\")\n",
    "    subframe = merged_df.copy()\n",
    "    subframe = subframe[subframe[\"event_num\"] == i]\n",
    "    seq_val = np.unique(subframe[\"seqNum\"])\n",
    "    dayObs = str(\n",
    "        real_events_frame.loc[real_events_frame[\"event_num\"] == i, \"day_obs\"].values[0]\n",
    "    )\n",
    "    if len(subframe) > 0:\n",
    "        offset = float(\n",
    "            real_events_frame.loc[real_events_frame[\"event_num\"] == i, \"offset\"].values\n",
    "        )\n",
    "        plt.plot(\n",
    "            subframe[\"delta_time\"] - offset,\n",
    "            subframe[\"measuredForce2\"] - 800 * j,\n",
    "            label=f\"{dayObs}, {seq_val[0]}\",\n",
    "        )\n",
    "        j += 1\n",
    "if l == 1:\n",
    "    plt.legend()\n",
    "if l == 4:\n",
    "    plt.legend(fontsize=9.2, loc=7, title=\"seqNum, eventNum\")\n",
    "plt.axvline(0, c=\"k\", ls=\"dashed\")\n",
    "plt.axvline(1, c=\"r\", ls=\"dashed\")\n",
    "plt.axvline(-1, c=\"r\", ls=\"dashed\")\n",
    "# plt.savefig(f\"./sitcomtn81_data/plots/diagnostic_{day}_{k}_{l}_{int(k/l/30)}.png\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b73a41-74d7-4c79-98d7-0cfff3094c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in np.unique(merged_df[\"event_num\"]):\n",
    "    sel = merged_df[\"event_num\"] == i\n",
    "    stats_df = get_stats(merged_df[sel])\n",
    "    stats_df[\"day_obs\"] = events_frame[\"day_obs\"].values[i]\n",
    "    stats_df[\"seq_num\"] = events_frame[\"seq_num\"].values[i]\n",
    "    # stats_df[\"elevation_velocity\"] = events_frame['elevation_velocity'].values[i]\n",
    "    stats_df[\"time\"] = events_frame[\"time\"].values[i] + 3\n",
    "    df_list.append(stats_df)\n",
    "stats_df = pd.concat(df_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
