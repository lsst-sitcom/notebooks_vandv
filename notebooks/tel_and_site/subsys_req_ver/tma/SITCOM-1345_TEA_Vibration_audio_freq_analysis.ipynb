{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2b0c6-deb4-438a-b7c2-147ff8f3a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from wave import open as open_wave\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import stft\n",
    "from pydub import AudioSegment\n",
    "from scipy.fft import fft, fftfreq\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import welch\n",
    "import scipy.io.wavfile as wf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bfe981-06f6-4e62-9161-32290472d664",
   "metadata": {},
   "source": [
    "## Opening the audio file to construct the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2b548-a29c-4f45-a602-d38e387e26fe",
   "metadata": {},
   "source": [
    "### There are three audio files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1dbf2-12c2-43e8-acd0-9b20d36b4be6",
   "metadata": {},
   "source": [
    "##### The names of the audio files is the format 'Audio_<date>_<time>.wav'. The three instance are as follows - \n",
    "##### event 1: 2024-03-09_23.41.07\n",
    "##### event 2: 2024-03-10_11.21.01\n",
    "##### event 3: 2024-03-10_13.13.06\n",
    "\n",
    "##### Each of the above instances are used to create the analysis below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93990ff7-65a4-4a04-877f-bae320455835",
   "metadata": {},
   "outputs": [],
   "source": [
    "n= str('2024-03-10_13.13.06') # event instances mentioned above number of the audio file.  \n",
    "ch=2 # Channel number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563ede2-2869-46aa-a8fc-24041f234d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw = open_wave(f'Audio_{n}_Ch{ch}.wav','rb')\n",
    "#f_rate=raw.getframerate() \n",
    "#signal= raw.readframes(-1)\n",
    "#signal = np.frombuffer(signal, dtype=np.int16)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ee444-faf3-49f8-9bb6-d9ad82a07f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wf.read(f'Audio_{n}.wav')\n",
    "#signal = data[:, 0] ## choose this for ch=1\n",
    "signal = data[:, 1] ## choose this for ch=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56823d-feee-4cf2-aea8-4cf3a65a9669",
   "metadata": {},
   "source": [
    "### creating a time vector to plot the signal  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a110f07-28a5-45c1-b950-d3debb53a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace( \n",
    "        0, # start \n",
    "        len(signal) / rate, \n",
    "        num = len(signal) \n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd571a-1ee0-463f-8a7b-848d12aa972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1) \n",
    "plt.title('TEA clip '+ n+': Ch'+str(ch)) \n",
    "plt.xlabel('Time (s)') \n",
    "plt.ylabel('Amplitude')\n",
    "plt.plot(time, signal) \n",
    "plt.savefig('./plots/tea_'+n+'_ch'+str(ch)+'_signal.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b68d3-ca9f-451a-9c15-89b8030d9222",
   "metadata": {},
   "source": [
    "## METHOD 1: Finding dominant frequencies using FFT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ac847-4f39-4764-9290-b5d3869aa924",
   "metadata": {},
   "source": [
    "##### we use fourier transform analysis to identify coonstituent frequencies in the above signal. Note that we do not use the 'rfft' or real FFT even if the signal is real. The reason for this is to retain the directionality of frequencies i.e. +ve or forward going frequencies or -ve or reverse frequencies. These can potentially be a way of identifying/separating out the frequency of the vibrations. \n",
    "\n",
    "##### for example: the instrument can have a base continuum sound with a specific frequency(s) that can be identied as positive while an unexpected/resistive vibration could be detected as a -ve frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b35aa-b3bb-49b0-936d-b487de4e357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_signal = np.int16((signal / signal.max()) * 32767)\n",
    "sig_fft = fft(norm_signal)\n",
    "sample_freq = fftfreq(len(signal), 1/rate)\n",
    "power = np.abs(sig_fft)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73531120-234b-4665-a65c-5d9afd1f3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(sample_freq, power)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power')\n",
    "plt.title('TEA clip '+n+':Ch '+str(ch))\n",
    "plt.savefig('./plots/tea_'+n+'_ch'+str(ch)+'_fft_freq.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c13af-340f-4e48-b011-259c16a1d266",
   "metadata": {},
   "source": [
    "### Conclusion: This analysis cannot give us a conlusive identification of the frequency of the vibrations as it just shows us the frequency composition of the signal.\n",
    "#### This is applicable to all the three audio signals even if two of them were captured during the top-end assembly vibration event. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a7f198-cbb1-4016-8688-0874f950d25a",
   "metadata": {},
   "source": [
    "## METHOD 2: Finding vibrations in frequency domain using Power spectral density (PSD) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056a8a9-48a6-40ae-8476-657e6c6cd2c8",
   "metadata": {},
   "source": [
    "#### We use Power Spectrum desnity as another method to determine the power distribution across frequency. This method is also more useful to identify the vibration if any across the entire frequency range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd30919-7761-4048-a858-37b647bbc465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, Pxx_den = welch(signal, rate, nperseg=2048)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.semilogy(f, Pxx_den)\n",
    "#plt.ylim([0.5e-3, 1])\n",
    "plt.title('TEA clip '+n+':Chan '+str(ch))\n",
    "plt.xlabel('Frequency [(Hz)')\n",
    "plt.ylabel('PSD (V**2/Hz)')\n",
    "plt.savefig('./plots/tea_'+n+'_ch'+str(ch)+'_psd.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807dd7c-46e9-4b30-a793-e89677bec99e",
   "metadata": {},
   "source": [
    "## SPECTROGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3253f-199d-4803-910b-8edd7a60aa0d",
   "metadata": {},
   "source": [
    "#### A spectrogram is essentially a plotv that shows the distribution of frequency across time. Any time-sensitive frequency changes should hence be identifiable on this plot. \n",
    "#### The following method uses a short-time fourier transform and the colour shading on the plot indicate the amplitude (bright yellow being the highest amplitude)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd6646-542f-4d06-bf56-f9f2c4219b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Zxx = stft(signal, rate, window=\"hamming\", nperseg=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492d010-727d-4c48-bfb3-1ddb5f57bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=128, figsize=(6, 6))\n",
    "pcm=ax.pcolormesh(t, f, np.abs(Zxx), shading=\"gouraud\", norm=mpl.colors.LogNorm(vmin=0.1))\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "fig.colorbar(pcm, ax=ax)\n",
    "plt.savefig('./plots/tea_'+n+'_ch'+str(ch)+'_spectrogram.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b85c2-4e46-46a0-8c68-fba93c09039d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a640b1-f9a6-4842-8b0d-3c351ef2a590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
