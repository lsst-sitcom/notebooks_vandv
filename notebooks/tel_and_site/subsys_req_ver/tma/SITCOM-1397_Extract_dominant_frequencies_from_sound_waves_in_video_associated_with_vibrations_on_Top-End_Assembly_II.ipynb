{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a757a37c",
   "metadata": {},
   "source": [
    "Before running this script you have to install librosa python package using pip command:\n",
    "\n",
    "!pip install librosa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68631522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from scipy.signal import lombscargle\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d6b188",
   "metadata": {},
   "source": [
    "# 1. Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684bf543",
   "metadata": {},
   "source": [
    "In this section we compute the spectrograms of the three audio signals separately and side by side. Spectrograms did not show any conclusive result on the vibration detected on the TEA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dab0bc",
   "metadata": {},
   "source": [
    "Spectrogram of the audio Audio_2024-03-10_13.13.06.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'Audio_2024-03-10_13.13.06.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "D = np.abs(librosa.stft(y))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f')\n",
    "plt.title('Spectrogram (Waterfall Plot) - 2024-03-10_at_13.13.06')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53102d47",
   "metadata": {},
   "source": [
    "Spectrogram of the audio Audio_2024-03-10_11.21.01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'Audio_2024-03-10_11.21.01.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "D = np.abs(librosa.stft(y))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f')\n",
    "plt.title('Spectrogram (Waterfall Plot) - 2024-03-10_at_11.21.01')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74603b",
   "metadata": {},
   "source": [
    "Spectrogram of the audio Audio_2024-03-09_23.41.07.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45336875",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'Audio_2024-03-09_23.41.07.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "D = np.abs(librosa.stft(y))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f')\n",
    "plt.title('Spectrogram (Waterfall Plot) - 2024-03-09_at_23.41.07')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1263c77",
   "metadata": {},
   "source": [
    "Spectrograms of the all three audios side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['Audio_2024-03-10_13.13.06.wav', 'Audio_2024-03-10_11.21.01.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    y = signals[i]\n",
    "    sr = sample_rates[i]\n",
    "    \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    \n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=axes[i])\n",
    "    axes[i].set_title(f'Spectrogram of Audio {i+1}')\n",
    "    fig.colorbar(img, ax=axes[i], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14f899",
   "metadata": {},
   "source": [
    "# 2. FFT of audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d30e8",
   "metadata": {},
   "source": [
    "In this section we compute the simple FFT analyses of the three audio signals, extract the dominant frequency from them, and print it. None of the extracted dominant frequencies did not match the expected low frequency heard on the TEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['Audio_2024-03-10_13.13.06.wav', 'Audio_2024-03-10_11.21.01.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "ffts = []\n",
    "frequencies = []\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "    \n",
    "    fft = np.fft.fft(y)\n",
    "    ffts.append(np.abs(fft))\n",
    "    \n",
    "    freq = np.fft.fftfreq(len(fft), 1/sr)\n",
    "    frequencies.append(freq)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    axes[i].plot(frequencies[i], ffts[i], label=f'Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    axes[i].set_title(f'FFT of Audio {i+1}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e48961",
   "metadata": {},
   "source": [
    "Extract dominant Frequency using FFT for all three audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['Audio_2024-03-10_13.13.06.wav', 'Audio_2024-03-10_11.21.01.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "ffts = []\n",
    "frequencies = []\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "    fft = np.fft.fft(y)\n",
    "    ffts.append(np.abs(fft))\n",
    "\n",
    "    freq = np.fft.fftfreq(len(fft), 1/sr)\n",
    "    frequencies.append(freq)\n",
    "\n",
    "min_freq = 0\n",
    "max_freq = 500\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    \n",
    "    idx = np.where((frequencies[i] >= min_freq) & (frequencies[i] <= max_freq))\n",
    "    \n",
    "    \n",
    "    axes[i].plot(frequencies[i][idx], ffts[i][idx], label=f'Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    axes[i].set_title(f'FFT of Audio {i+1}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a2ae7f",
   "metadata": {},
   "source": [
    "Print the dominant Frequency beside the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ddaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['Audio_2024-03-10_13.13.06.wav', 'Audio_2024-03-10_11.21.01.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "ffts = []\n",
    "frequencies = []\n",
    "dominant_frequencies = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "    fft = np.fft.fft(y)\n",
    "    ffts.append(np.abs(fft))\n",
    "\n",
    "    freq = np.fft.fftfreq(len(fft), 1/sr)\n",
    "    frequencies.append(freq)\n",
    "\n",
    "    idx = np.argmax(np.abs(fft))\n",
    "    dominant_frequency = freq[idx]\n",
    "    dominant_frequencies.append(dominant_frequency)\n",
    "\n",
    "    print(f\"Dominant frequency for {file}: {dominant_frequency} Hz\")\n",
    "\n",
    "min_freq = 0\n",
    "max_freq = 1500\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "\n",
    "    idx = np.where((frequencies[i] >= min_freq) & (frequencies[i] <= max_freq))\n",
    "    \n",
    "    axes[i].plot(frequencies[i][idx], ffts[i][idx], label=f'Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    axes[i].set_title(f'FFT of Audio {i+1}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad3e5f",
   "metadata": {},
   "source": [
    "# 3. Short-time FT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c45e32",
   "metadata": {},
   "source": [
    "In this section we repeated the previous analyses but now using the Short-time FT. The results stay inconclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ae964",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['Audio_2024-03-10_13.13.06.wav', 'Audio_2024-03-10_11.21.01.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "dominant_frequencies = []\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "    \n",
    "\n",
    "    S = np.abs(librosa.stft(y))\n",
    "    \n",
    "\n",
    "    avg_energy = np.mean(S, axis=1)\n",
    "    \n",
    "\n",
    "    dominant_frequency_idx = np.argmax(avg_energy)\n",
    "    dominant_frequency = librosa.fft_frequencies(sr=sr, n_fft=S.shape[0])[dominant_frequency_idx]\n",
    "    dominant_frequencies.append(dominant_frequency)\n",
    "    \n",
    "    print(f\"Dominant frequency for {file}: {dominant_frequency} Hz\")\n",
    "\n",
    "\n",
    "min_freq = 0\n",
    "max_freq = 5000\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    \n",
    "    S = np.abs(librosa.stft(signals[i]))\n",
    "    avg_energy = np.mean(S, axis=1)\n",
    "    freqs = librosa.fft_frequencies(sr=sample_rates[i], n_fft=S.shape[0])\n",
    "    \n",
    "    \n",
    "    idx = np.where((freqs >= min_freq) & (freqs <= max_freq))\n",
    "    \n",
    "    \n",
    "    axes[i].plot(freqs[idx], avg_energy[idx], label=f'Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Average Energy')\n",
    "    axes[i].set_title(f'Average Energy Spectrum of Audio {i+1}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bb2ba",
   "metadata": {},
   "source": [
    "# 4. Power spectral density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835765d",
   "metadata": {},
   "source": [
    "In this section, we try to catch low frequency from the audio files using PSD. Again the results did not show the extremes in the low-frequency range, even when zoom-in into the PSD plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f77f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['Audio_2024-03-10_13.13.06.wav', 'Audio_2024-03-10_11.21.01.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "\n",
    "n_fft = 1024  # Length of the FFT window\n",
    "n_per_seg = n_fft  # Length of each segment for Welch's method\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    y = signals[i]\n",
    "    sr = sample_rates[i]\n",
    "\n",
    "    freqs, psd = welch(y, fs=sr, nperseg=n_per_seg)\n",
    "\n",
    "    axes[i].semilogy(freqs, psd)\n",
    "    axes[i].set_title(f'Power Spectral Density of Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Power/Frequency (dB/Hz)')\n",
    "    axes[i].set_xlim([0, sr/2])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0034e6",
   "metadata": {},
   "source": [
    "Zoom in PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['Audio_2024-03-10_13.13.06.wav', 'Audio_2024-03-10_11.21.01.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "\n",
    "n_fft = 2048  # Length of the FFT window\n",
    "n_per_seg = n_fft  # Length of each segment for Welch's method\n",
    "\n",
    "\n",
    "low_freq = 0\n",
    "high_freq = 1500\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    y = signals[i]\n",
    "    sr = sample_rates[i]\n",
    "    \n",
    "    \n",
    "    freqs, psd = welch(y, fs=sr, nperseg=n_per_seg)\n",
    "    \n",
    "    \n",
    "    axes[i].semilogy(freqs, psd)\n",
    "    axes[i].set_title(f'Power Spectral Density of Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Power/Frequency (dB/Hz)')\n",
    "    \n",
    "    \n",
    "    axes[i].set_xlim([low_freq, high_freq])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9afcb2d",
   "metadata": {},
   "source": [
    "# 5. Extract background noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa1bed",
   "metadata": {},
   "source": [
    "Here we try to denoise the three signals and to repeat some of the previous analyses. We used the first second of the video as a model for the background noise. The results of all the analyses on the denoised signals stay inconclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde3018",
   "metadata": {},
   "source": [
    "Denoising of the Audio_2024-03-10_13.13.06.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = './Audio_2024-03-10_13.13.06.wav'\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "\n",
    "noise_duration = 1.0  # seconds\n",
    "noise_sample = int(noise_duration * sr)\n",
    "noise_profile = y[:noise_sample]\n",
    "\n",
    "\n",
    "D = librosa.stft(y)\n",
    "D_noise = librosa.stft(noise_profile)\n",
    "\n",
    "\n",
    "mean_noise_spectrum = np.mean(np.abs(D_noise), axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "D_denoised = np.abs(D) - mean_noise_spectrum\n",
    "\n",
    "# Prevent negative values in the spectrum\n",
    "D_denoised = np.maximum(D_denoised, 0)\n",
    "\n",
    "\n",
    "y_denoised = librosa.istft(D_denoised * np.exp(1.j * np.angle(D)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.waveshow(y_denoised, sr=sr)\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the denoised signal using soundfile\n",
    "sf.write('denoised_2024-03-10_at_13.13.06_audio.wav', y_denoised, sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1a43e",
   "metadata": {},
   "source": [
    "Spectrogram of the denoised audio Audio_2024-03-10_13.13.06.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c67d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'denoised_2024-03-10_at_13.13.06_audio.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "\n",
    "D = np.abs(librosa.stft(y))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f')\n",
    "plt.title('Spectrogram (Waterfall Plot)-denoised-2024-03-10_at_13.13.06')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b84e9d",
   "metadata": {},
   "source": [
    "Original signal VS denoised signal - spectrograms - audio Audio_2024-03-10_13.13.06.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['denoised_2024-03-10_at_13.13.06_audio.wav', 'Audio_2024-03-10_13.13.06.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    y = signals[i]\n",
    "    sr = sample_rates[i]\n",
    "    \n",
    "    \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    \n",
    "    \n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=axes[i])\n",
    "    axes[i].set_title(f'Spectrogram of Audio {i+1}')\n",
    "    fig.colorbar(img, ax=axes[i], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00926971",
   "metadata": {},
   "source": [
    "FFt of denoised signal of the audio Audio_2024-03-10_13.13.06.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['denoised_2024-03-10_at_13.13.06_audio.wav', 'Audio_2024-03-10_13.13.06.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "ffts = []\n",
    "frequencies = []\n",
    "dominant_frequencies = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "    \n",
    "    \n",
    "    fft = np.fft.fft(y)\n",
    "    ffts.append(np.abs(fft))\n",
    "    \n",
    "    \n",
    "    freq = np.fft.fftfreq(len(fft), 1/sr)\n",
    "    frequencies.append(freq)\n",
    "    \n",
    "    \n",
    "    idx = np.argmax(np.abs(fft))\n",
    "    dominant_frequency = freq[idx]\n",
    "    dominant_frequencies.append(dominant_frequency)\n",
    "\n",
    "    print(f\"Dominant frequency for {file}: {dominant_frequency} Hz\")\n",
    "\n",
    "\n",
    "min_freq = 0\n",
    "max_freq = 1500\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    \n",
    "    idx = np.where((frequencies[i] >= min_freq) & (frequencies[i] <= max_freq))\n",
    "    \n",
    "    \n",
    "    axes[i].plot(frequencies[i][idx], ffts[i][idx], label=f'Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    axes[i].set_title(f'FFT of Audio {i+1}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072ee28",
   "metadata": {},
   "source": [
    "Denoising the second audio - Audio_2024-03-10_11.21.01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8609803",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = './Audio_2024-03-10_11.21.01.wav'\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "\n",
    "noise_duration = 1.0  # seconds\n",
    "noise_sample = int(noise_duration * sr)\n",
    "noise_profile = y[:noise_sample]\n",
    "\n",
    "\n",
    "D = librosa.stft(y)\n",
    "D_noise = librosa.stft(noise_profile)\n",
    "\n",
    "\n",
    "mean_noise_spectrum = np.mean(np.abs(D_noise), axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "D_denoised = np.abs(D) - mean_noise_spectrum\n",
    "\n",
    "\n",
    "D_denoised = np.maximum(D_denoised, 0)\n",
    "\n",
    "\n",
    "y_denoised = librosa.istft(D_denoised * np.exp(1.j * np.angle(D)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.waveshow(y_denoised, sr=sr)\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the denoised signal using soundfile\n",
    "sf.write('denoised_2024-03-10_at_11.21.01_audio.wav', y_denoised, sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e258cb",
   "metadata": {},
   "source": [
    "Spectrogram of the denoised audio Audio_2024-03-10_11.21.01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'denoised_2024-03-10_at_11.21.01_audio.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Compute the STFT of the audio signal\n",
    "D = np.abs(librosa.stft(y))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f')\n",
    "plt.title('Spectrogram (Waterfall Plot)- Denoised_2024-03-10_at_11.21.01')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b557f16",
   "metadata": {},
   "source": [
    "Spectrograms: denoised audio VS original - Audio_2024-03-10_11.21.01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f86f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['denoised_2024-03-10_at_11.21.01_audio.wav', 'Audio_2024-03-10_11.21.01.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    y = signals[i]\n",
    "    sr = sample_rates[i]\n",
    "    \n",
    "    \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    \n",
    "   \n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=axes[i])\n",
    "    axes[i].set_title(f'Spectrogram of Audio {i+1}')\n",
    "    fig.colorbar(img, ax=axes[i], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ad03c",
   "metadata": {},
   "source": [
    "FFT denoised VS original - Audio_2024-03-10_11.21.01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6216104",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['denoised_2024-03-10_at_11.21.01_audio.wav', 'Audio_2024-03-10_11.21.01.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "ffts = []\n",
    "frequencies = []\n",
    "dominant_frequencies = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "    \n",
    "    \n",
    "    fft = np.fft.fft(y)\n",
    "    ffts.append(np.abs(fft))\n",
    "    \n",
    "  \n",
    "    freq = np.fft.fftfreq(len(fft), 1/sr)\n",
    "    frequencies.append(freq)\n",
    "    \n",
    "\n",
    "    idx = np.argmax(np.abs(fft))\n",
    "    dominant_frequency = freq[idx]\n",
    "    dominant_frequencies.append(dominant_frequency)\n",
    "\n",
    "    print(f\"Dominant frequency for {file}: {dominant_frequency} Hz\")\n",
    "\n",
    "\n",
    "min_freq = 0\n",
    "max_freq = 1500\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    \n",
    "    idx = np.where((frequencies[i] >= min_freq) & (frequencies[i] <= max_freq))\n",
    "    \n",
    "    \n",
    "    axes[i].plot(frequencies[i][idx], ffts[i][idx], label=f'Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    axes[i].set_title(f'FFT of Audio {i+1}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f17196",
   "metadata": {},
   "source": [
    "Denoising of the audio Audio_2024-03-09_23.41.07.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = './Audio_2024-03-09_23.41.07.wav'\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "\n",
    "noise_duration = 1.0  # seconds\n",
    "noise_sample = int(noise_duration * sr)\n",
    "noise_profile = y[:noise_sample]\n",
    "\n",
    "\n",
    "D = librosa.stft(y)\n",
    "D_noise = librosa.stft(noise_profile)\n",
    "\n",
    "\n",
    "mean_noise_spectrum = np.mean(np.abs(D_noise), axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "D_denoised = np.abs(D) - mean_noise_spectrum\n",
    "\n",
    "\n",
    "D_denoised = np.maximum(D_denoised, 0)\n",
    "\n",
    "\n",
    "y_denoised = librosa.istft(D_denoised * np.exp(1.j * np.angle(D)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.waveshow(y_denoised, sr=sr)\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the denoised signal using soundfile\n",
    "sf.write('denoised_2024-03-09_at_23.41.07_audio.wav', y_denoised, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf6b0c",
   "metadata": {},
   "source": [
    "Spectrogram of the denoised audio Audio_2024-03-09_23.41.07.wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'denoised_2024-03-09_at_23.41.07_audio.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "\n",
    "D = np.abs(librosa.stft(y))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f')\n",
    "plt.title('Spectrogram (Waterfall Plot)- Denoised_2024-03-09_at_23.41.07')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7b8f6",
   "metadata": {},
   "source": [
    "Spectrogram of denoised VS original audio - Audio_2024-03-09_23.41.07.wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaeff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['denoised_2024-03-09_at_23.41.07_audio.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "    y = signals[i]\n",
    "    sr = sample_rates[i]\n",
    "    \n",
    "   \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    \n",
    "  \n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=axes[i])\n",
    "    axes[i].set_title(f'Spectrogram of Audio {i+1}')\n",
    "    fig.colorbar(img, ax=axes[i], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e311bb8",
   "metadata": {},
   "source": [
    "FFT of the original VS denoised - Audio_2024-03-09_23.41.07.wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c21783",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['denoised_2024-03-09_at_23.41.07_audio.wav', 'Audio_2024-03-09_23.41.07.wav']\n",
    "\n",
    "\n",
    "signals = []\n",
    "sample_rates = []\n",
    "ffts = []\n",
    "frequencies = []\n",
    "dominant_frequencies = []\n",
    "\n",
    "for file in audio_files:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    signals.append(y)\n",
    "    sample_rates.append(sr)\n",
    "    \n",
    "  \n",
    "    fft = np.fft.fft(y)\n",
    "    ffts.append(np.abs(fft))\n",
    "    \n",
    "\n",
    "    freq = np.fft.fftfreq(len(fft), 1/sr)\n",
    "    frequencies.append(freq)\n",
    "    \n",
    "\n",
    "    idx = np.argmax(np.abs(fft))\n",
    "    dominant_frequency = freq[idx]\n",
    "    dominant_frequencies.append(dominant_frequency)\n",
    "\n",
    "    print(f\"Dominant frequency for {file}: {dominant_frequency} Hz\")\n",
    "\n",
    "\n",
    "min_freq = 0\n",
    "max_freq = 1500\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "for i in range(len(audio_files)):\n",
    "   \n",
    "    idx = np.where((frequencies[i] >= min_freq) & (frequencies[i] <= max_freq))\n",
    "    \n",
    "   \n",
    "    axes[i].plot(frequencies[i][idx], ffts[i][idx], label=f'Audio {i+1}')\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    axes[i].set_title(f'FFT of Audio {i+1}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
